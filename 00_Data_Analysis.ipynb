{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e7309b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lux\n",
    "\n",
    "import copy\n",
    "\n",
    "import csv\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812744b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c5383966544e5391c3d417dfbb13fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277e909ed0834083b82c7074d2efe47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/test_amazon_small.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15248578-c466-4fdf-bd11-9017468dd2d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re.sub(r\"[.]+\",\". \", df[\"review_text\"].iloc[54]), df[\"review_text\"].iloc[54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c87102e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5f6f915f9a4ff28f17f4c4beead8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253f7bec5de4495c8e86a0e9ce9af5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_duplicate = pd.DataFrame({\"review\":df[\"review_text\"], \"polarity\":df[\"class_ind\"]})#copy.deepcopy(df)\n",
    "# df_duplicate = df_duplicate.iloc[:8000]\n",
    "# df_duplicate.columns = ['class_ind', 'review_title', 'review_text']\n",
    "df_duplicate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fdd612ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"test_amazon_small.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38162431",
   "metadata": {
    "tags": []
   },
   "source": [
    "A. Using SQL operation to explore\n",
    "--------------------\n",
    "\n",
    "1. Get a view of table\n",
    "2. Explore some insights from dataset\n",
    "3. Find answer to questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b214cdd-fc7c-46b3-b46e-8388a4d004b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Inserted in the table: \n",
      "('Raju', '7th', 'A')\n",
      "('Shyam', '8th', 'B')\n",
      "('Baburao', '9th', 'C')\n"
     ]
    }
   ],
   "source": [
    "# Connecting to sqlite\n",
    "conn = sqlite3.connect('geeks2.db')\n",
    "  \n",
    "# Creating a cursor object using the \n",
    "# cursor() method\n",
    "cursor = conn.cursor()\n",
    "  \n",
    "# Creating table\n",
    "table =\"\"\"CREATE TABLE STUDENT(NAME VARCHAR(255), CLASS VARCHAR(255),\n",
    "SECTION VARCHAR(255));\"\"\"\n",
    "cursor.execute(table)\n",
    "  \n",
    "# Queries to INSERT records.\n",
    "cursor.execute('''INSERT INTO STUDENT VALUES ('Raju', '7th', 'A')''')\n",
    "cursor.execute('''INSERT INTO STUDENT VALUES ('Shyam', '8th', 'B')''')\n",
    "cursor.execute('''INSERT INTO STUDENT VALUES ('Baburao', '9th', 'C')''')\n",
    "  \n",
    "# Display data inserted\n",
    "print(\"Data Inserted in the table: \")\n",
    "data=cursor.execute('''SELECT * FROM STUDENT''')\n",
    "for row in data:\n",
    "    print(row)\n",
    "  \n",
    "# Commit your changes in the database    \n",
    "conn.commit()\n",
    "  \n",
    "# Closing the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c44df33c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# creating connection\n",
    "amz_con = sqlite3.connect(\"amazon.db\")\n",
    "cursor = amz_con.cursor()\n",
    "\n",
    "print(amz_con.total_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bf1160c-93f1-47f3-891c-5859aab4aaa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table Amazon_Polarity already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_520/4107980556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m table =\"\"\"CREATE TABLE Amazon_Polarity(class_ind INT, review_title VARCHAR(455),\n\u001b[1;32m      3\u001b[0m review_text VARCHAR(955));\"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: table Amazon_Polarity already exists"
     ]
    }
   ],
   "source": [
    "# Creating table\n",
    "table =\"\"\"CREATE TABLE Amazon_Polarity(class_ind INT, review_title VARCHAR(455),\n",
    "review_text VARCHAR(955));\"\"\"\n",
    "cursor.execute(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "619f5888-42a7-413d-9848-14428a2341c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "near \"t\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_520/1472733135.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Queries to INSERT records.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'''INSERT INTO STUDENT VALUES ('{row[col[0]]}', '{row[col[1]]}', '{row[col[2]]}')'''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: near \"t\": syntax error"
     ]
    }
   ],
   "source": [
    "for ind, row in df.loc[:1].iterrows():\n",
    "    # Queries to INSERT records.\n",
    "    cursor.execute(f'''INSERT INTO STUDENT VALUES ('{row[col[0]]}', '{row[col[1]]}', '{row[col[2]]}')''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d413835c-0918-42ed-9a87-082c9b805be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ==== One of the best game music soundtracks - for a game I didn't really play ==== Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\n",
      "1 ==== Batteries died within a year ... ==== I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.\n",
      "2 ==== works fine, but Maha Energy is better ==== Check out Maha Energy's website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.\n"
     ]
    }
   ],
   "source": [
    "col = df.columns\n",
    "for ind, row in df.loc[:2].iterrows():\n",
    "    print(row[col[0]], '====',row[col[1]],'====', row[col[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dc8ffea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"amazon_small.csv\", 'r') as file:\n",
    "    data = csv.DictReader(file)\n",
    "    amz_review = [(i, i, i) for i in data]\n",
    "    print(amz_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdaa9c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "parameters are of unsupported type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_756/1573705028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparameter_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class_ind'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review_title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review_text'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mamz_con\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     cursor.executemany(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"insert into amazon_review (class_ind, review_title, review_text) VALUES(?, ?, ?);\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         parameter_list)\n",
      "\u001b[0;31mValueError\u001b[0m: parameters are of unsupported type"
     ]
    }
   ],
   "source": [
    "# cursor.execute('create table amazon_review(class_ind int, review_title varchar2(100), review_text varchar2(9000))')\n",
    "parameter_list = [({'class_ind', 'review_title', 'review_text'})]\n",
    "with amz_con:\n",
    "    cursor.executemany(\n",
    "        \"insert into amazon_review (class_ind, review_title, review_text) VALUES(?, ?, ?);\", \n",
    "        parameter_list)\n",
    "    amz_con.commit()\n",
    "# cursor.execute(\"select * from student;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11008c53",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "amz_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55af9881-9ebb-4577-af77-24e7e90abd34",
   "metadata": {
    "tags": []
   },
   "source": [
    "B. DATA Processing\n",
    "----------------\n",
    "Steps of processing text dataset\n",
    "1. Loading\n",
    "2. Cleaning\n",
    "3. Tokenization\n",
    "4. Vectorization/Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e56f04-9b46-4d25-bb80-d59ed7ec935b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To lemmatize whole sentence\n",
    "# !pip3 install -U pywsd\n",
    "# !pip3 install -U wn==0.0.22\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8b2dab8e-01d4-4c43-b4be-096724f4a4b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pywsd.utils import lemmatize_sentence\n",
    "\n",
    "# for tokenization\n",
    "from spacy.lang.en import English\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "# for vectorization\n",
    "from gensim import models\n",
    "import dataloader\n",
    "import fasttext\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from transformers import GPT2TokenizerFast, BertTokenizer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48153e6d-d2b9-44d7-a6d8-9662c745d246",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9c2f13e1364aea9dc1ed2cbfd812ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bb285184fb4194b543744ed896a118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7b40b027-5c4c-46db-b592-09ffcd5d3dec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the best game music soundtracks - for a game I didn't really play ======== Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\n",
      "Batteries died within a year ... ======== I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.\n",
      "works fine, but Maha Energy is better ======== Check out Maha Energy's website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.\n",
      "Great for the non-audiophile ======== Reviewed quite a bit of the combo players and was hesitant due to unfavorable reviews and size of machines. I am weaning off my VHS collection, but don't want to replace them with DVD's. This unit is well built, easy to setup and resolution and special effects (no progressive scan for HDTV owners) suitable for many people looking for a versatile product.Cons- No universal remote.\n",
      "DVD Player crapped out after one year ======== I also began having the incorrect disc problems that I've read about on here. The VCR still works, but hte DVD side is useless. I understand that DVD players sometimes just quit on you, but after not even one year? To me that's a sign on bad quality. I'm giving up JVC after this as well. I'm sticking to Sony or giving another brand a shot.\n",
      "Incorrect Disc ======== I love the style of this, but after a couple years, the DVD is giving me problems. It doesn't even work anymore and I use my broken PS2 Now. I wouldn't recommend this, I'm just going to upgrade to a recorder now. I wish it would work but I guess i'm giving up on JVC. I really did like this one... before it stopped working. The dvd player gave me problems probably after a year of having it.\n",
      "DVD menu select problems ======== I cannot scroll through a DVD menu that is set up vertically. The triangle keys will only select horizontally. So I cannot select anything on most DVD's besides play. No special features, no language select, nothing, just play.\n",
      "Unique Weird Orientalia from the 1930's ======== Exotic tales of the Orient from the 1930's. \"Dr Shen Fu\", a Weird Tales magazine reprint, is about the elixir of life that grants immortality at a price. If you're tired of modern authors who all sound alike, this is the antidote for you. Owen's palette is loaded with splashes of Chinese and Japanese colours. Marvelous.\n",
      "Not an \"ultimate guide\" ======== Firstly,I enjoyed the format and tone of the book (how the author addressed the reader). However, I did not feel that she imparted any insider secrets that the book promised to reveal. If you are just starting to research law school, and do not know all the requirements of admission, then this book may be a tremendous help. If you have done your homework and are looking for an edge when it comes to admissions, I recommend some more topic-specific books. For example, books on how to write your personal statment, books geared specifically towards LSAT preparation (Powerscore books were the most helpful for me), and there are some websites with great advice geared towards aiding the individuals whom you are asking to write letters of recommendation. Yet, for those new to the entire affair, this book can definitely clarify the requirements for you.\n",
      "Great book for travelling Europe ======== I currently live in Europe, and this is the book I recommend for my visitors. It covers many countries, colour pictures, and is a nice starter for before you go, and once you are there.\n",
      "Not! ======== If you want to listen to El Duke , then it is better if you have access to his shower,this is not him, it is a gimmick,very well orchestrated.\n"
     ]
    }
   ],
   "source": [
    "for ind, row in df.loc[:10].iterrows():\n",
    "    print(row['review_title'],\"========\", row['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "26dfe3d7-07f3-47c1-b8a0-66e3991dec0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "def clean_text(text):\n",
    "    if text is None:\n",
    "        text = \"empty\"\n",
    "    else:\n",
    "        text = str(text)\n",
    "    text = re.sub(r\"[.]+\",\" . \", text)\n",
    "    translator = str.maketrans('','', string.punctuation)\n",
    "    clean_txt = text.translate(translator)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #print(clean_txt,[lemmatizer.lemmatize(w) for w in word_tokenize(clean_txt)])\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in word_tokenize(clean_txt)]\n",
    "    return \" \".join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "15876093-7a6c-4741-81c6-3ca9ce1057de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6741cc65cc415a8abbd9e0fcebaa98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b158cdc5bd54a86b485143956e44d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"review\"] = df[\"review\"].apply(clean_text)\n",
    "# df[\"review_text\"] = df[\"review_text\"].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c4b469-d2a1-4475-b207-3621f8c365f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "# 1. using split() function\n",
    "# 2. using nltk and spacy library\n",
    "# 3. using countvectorizer\n",
    "# 4. using Gensim\n",
    "# 5. using pytorch torchtext\n",
    "def tokenization(text,method=\"split\"):\n",
    "    if method == 'split':  #It won't consider punctuation of words as token\n",
    "        return text.split()\n",
    "    elif method == 'nltk': # It will consider punctuations as tokens\n",
    "        return word_tokenize(text)\n",
    "    elif method == \"spacy\":\n",
    "        nlp = English()\n",
    "        doc = nlp(text)\n",
    "        tokens = [token.text for token in doc]\n",
    "        return tokens\n",
    "    elif method == 'countvector':\n",
    "        cv = CountVectorizer(stop_words='english')\n",
    "        cv_matrix = cv.fit_transform(df['review_text'].iloc[:50])\n",
    "        return pd.DataFrame(cv_matrix.toarray(),columns=cv.get_feature_names()).columns\n",
    "    elif method == 'gensim':\n",
    "        return list(tokenize(text))\n",
    "    elif method == 'torchtext':\n",
    "        tokenizer = get_tokenizer(\"basic_english\")\n",
    "        return tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed509ffb-cacd-4ef3-a3b2-1083e261449d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I had never read this author but knew of many who did When I read that this book was being made into a movie it seemed a good opportunity to read her before seeing the screen mess up her work Now I pray that the screen does soI was extremely disappointed with this work It is unrealistic fails to capture the reader and at points when I should have been completely engrossed left me struggling with whether I wanted to pick it up I hope she has written better than this or else there are a lot of people who have not bothered reading some of the strong authors availableHer characters are not sympathetic they do not draw the readers attention and they are dull in overall scope I have too many other good books to read before I pick up another book from this author, \n",
      "Method: split \n",
      "Output: ['I', 'had', 'never', 'read', 'this', 'author', 'but', 'knew', 'of', 'many', 'who', 'did', 'When', 'I', 'read', 'that', 'this', 'book', 'was', 'being', 'made', 'into', 'a', 'movie', 'it', 'seemed', 'a', 'good', 'opportunity', 'to', 'read', 'her', 'before', 'seeing', 'the', 'screen', 'mess', 'up', 'her', 'work', 'Now', 'I', 'pray', 'that', 'the', 'screen', 'does', 'soI', 'was', 'extremely', 'disappointed', 'with', 'this', 'work', 'It', 'is', 'unrealistic', 'fails', 'to', 'capture', 'the', 'reader', 'and', 'at', 'points', 'when', 'I', 'should', 'have', 'been', 'completely', 'engrossed', 'left', 'me', 'struggling', 'with', 'whether', 'I', 'wanted', 'to', 'pick', 'it', 'up', 'I', 'hope', 'she', 'has', 'written', 'better', 'than', 'this', 'or', 'else', 'there', 'are', 'a', 'lot', 'of', 'people', 'who', 'have', 'not', 'bothered', 'reading', 'some', 'of', 'the', 'strong', 'authors', 'availableHer', 'characters', 'are', 'not', 'sympathetic', 'they', 'do', 'not', 'draw', 'the', 'readers', 'attention', 'and', 'they', 'are', 'dull', 'in', 'overall', 'scope', 'I', 'have', 'too', 'many', 'other', 'good', 'books', 'to', 'read', 'before', 'I', 'pick', 'up', 'another', 'book', 'from', 'this', 'author']\n",
      "Length_of_token: 146\n",
      "===========================================================================\n",
      "Text: I had never read this author but knew of many who did When I read that this book was being made into a movie it seemed a good opportunity to read her before seeing the screen mess up her work Now I pray that the screen does soI was extremely disappointed with this work It is unrealistic fails to capture the reader and at points when I should have been completely engrossed left me struggling with whether I wanted to pick it up I hope she has written better than this or else there are a lot of people who have not bothered reading some of the strong authors availableHer characters are not sympathetic they do not draw the readers attention and they are dull in overall scope I have too many other good books to read before I pick up another book from this author, \n",
      "Method: nltk \n",
      "Output: ['I', 'had', 'never', 'read', 'this', 'author', 'but', 'knew', 'of', 'many', 'who', 'did', 'When', 'I', 'read', 'that', 'this', 'book', 'was', 'being', 'made', 'into', 'a', 'movie', 'it', 'seemed', 'a', 'good', 'opportunity', 'to', 'read', 'her', 'before', 'seeing', 'the', 'screen', 'mess', 'up', 'her', 'work', 'Now', 'I', 'pray', 'that', 'the', 'screen', 'does', 'soI', 'was', 'extremely', 'disappointed', 'with', 'this', 'work', 'It', 'is', 'unrealistic', 'fails', 'to', 'capture', 'the', 'reader', 'and', 'at', 'points', 'when', 'I', 'should', 'have', 'been', 'completely', 'engrossed', 'left', 'me', 'struggling', 'with', 'whether', 'I', 'wanted', 'to', 'pick', 'it', 'up', 'I', 'hope', 'she', 'has', 'written', 'better', 'than', 'this', 'or', 'else', 'there', 'are', 'a', 'lot', 'of', 'people', 'who', 'have', 'not', 'bothered', 'reading', 'some', 'of', 'the', 'strong', 'authors', 'availableHer', 'characters', 'are', 'not', 'sympathetic', 'they', 'do', 'not', 'draw', 'the', 'readers', 'attention', 'and', 'they', 'are', 'dull', 'in', 'overall', 'scope', 'I', 'have', 'too', 'many', 'other', 'good', 'books', 'to', 'read', 'before', 'I', 'pick', 'up', 'another', 'book', 'from', 'this', 'author']\n",
      "Length_of_token: 146\n",
      "===========================================================================\n",
      "Text: I had never read this author but knew of many who did When I read that this book was being made into a movie it seemed a good opportunity to read her before seeing the screen mess up her work Now I pray that the screen does soI was extremely disappointed with this work It is unrealistic fails to capture the reader and at points when I should have been completely engrossed left me struggling with whether I wanted to pick it up I hope she has written better than this or else there are a lot of people who have not bothered reading some of the strong authors availableHer characters are not sympathetic they do not draw the readers attention and they are dull in overall scope I have too many other good books to read before I pick up another book from this author, \n",
      "Method: spacy \n",
      "Output: ['I', 'had', 'never', 'read', 'this', 'author', 'but', 'knew', 'of', 'many', 'who', 'did', 'When', 'I', 'read', 'that', 'this', 'book', 'was', 'being', 'made', 'into', 'a', 'movie', 'it', 'seemed', 'a', 'good', 'opportunity', 'to', 'read', 'her', 'before', 'seeing', 'the', 'screen', 'mess', 'up', 'her', 'work', 'Now', 'I', 'pray', 'that', 'the', 'screen', 'does', 'soI', 'was', 'extremely', 'disappointed', 'with', 'this', 'work', 'It', 'is', 'unrealistic', 'fails', 'to', 'capture', 'the', 'reader', 'and', 'at', 'points', 'when', 'I', 'should', 'have', 'been', 'completely', 'engrossed', 'left', 'me', 'struggling', 'with', 'whether', 'I', 'wanted', 'to', 'pick', 'it', 'up', 'I', 'hope', 'she', 'has', 'written', 'better', 'than', 'this', 'or', 'else', 'there', 'are', 'a', 'lot', 'of', 'people', 'who', 'have', 'not', 'bothered', 'reading', 'some', 'of', 'the', 'strong', 'authors', 'availableHer', 'characters', 'are', 'not', 'sympathetic', 'they', 'do', 'not', 'draw', 'the', 'readers', 'attention', 'and', 'they', 'are', 'dull', 'in', 'overall', 'scope', 'I', 'have', 'too', 'many', 'other', 'good', 'books', 'to', 'read', 'before', 'I', 'pick', 'up', 'another', 'book', 'from', 'this', 'author']\n",
      "Length_of_token: 146\n",
      "===========================================================================\n",
      "Text: I had never read this author but knew of many who did When I read that this book was being made into a movie it seemed a good opportunity to read her before seeing the screen mess up her work Now I pray that the screen does soI was extremely disappointed with this work It is unrealistic fails to capture the reader and at points when I should have been completely engrossed left me struggling with whether I wanted to pick it up I hope she has written better than this or else there are a lot of people who have not bothered reading some of the strong authors availableHer characters are not sympathetic they do not draw the readers attention and they are dull in overall scope I have too many other good books to read before I pick up another book from this author, \n",
      "Method: countvector \n",
      "Output: Index(['10', '100', '12', '13', '16', '1930s', '2003', '2200', '40', '50',\n",
      "       ...\n",
      "       'wouldnt', 'write', 'written', 'year', 'years', 'yep', 'yes', 'youll',\n",
      "       'youre', 'yr'],\n",
      "      dtype='object', length=1079)\n",
      "Length_of_token: 1079\n",
      "===========================================================================\n",
      "Text: I had never read this author but knew of many who did When I read that this book was being made into a movie it seemed a good opportunity to read her before seeing the screen mess up her work Now I pray that the screen does soI was extremely disappointed with this work It is unrealistic fails to capture the reader and at points when I should have been completely engrossed left me struggling with whether I wanted to pick it up I hope she has written better than this or else there are a lot of people who have not bothered reading some of the strong authors availableHer characters are not sympathetic they do not draw the readers attention and they are dull in overall scope I have too many other good books to read before I pick up another book from this author, \n",
      "Method: gensim \n",
      "Output: ['I', 'had', 'never', 'read', 'this', 'author', 'but', 'knew', 'of', 'many', 'who', 'did', 'When', 'I', 'read', 'that', 'this', 'book', 'was', 'being', 'made', 'into', 'a', 'movie', 'it', 'seemed', 'a', 'good', 'opportunity', 'to', 'read', 'her', 'before', 'seeing', 'the', 'screen', 'mess', 'up', 'her', 'work', 'Now', 'I', 'pray', 'that', 'the', 'screen', 'does', 'soI', 'was', 'extremely', 'disappointed', 'with', 'this', 'work', 'It', 'is', 'unrealistic', 'fails', 'to', 'capture', 'the', 'reader', 'and', 'at', 'points', 'when', 'I', 'should', 'have', 'been', 'completely', 'engrossed', 'left', 'me', 'struggling', 'with', 'whether', 'I', 'wanted', 'to', 'pick', 'it', 'up', 'I', 'hope', 'she', 'has', 'written', 'better', 'than', 'this', 'or', 'else', 'there', 'are', 'a', 'lot', 'of', 'people', 'who', 'have', 'not', 'bothered', 'reading', 'some', 'of', 'the', 'strong', 'authors', 'availableHer', 'characters', 'are', 'not', 'sympathetic', 'they', 'do', 'not', 'draw', 'the', 'readers', 'attention', 'and', 'they', 'are', 'dull', 'in', 'overall', 'scope', 'I', 'have', 'too', 'many', 'other', 'good', 'books', 'to', 'read', 'before', 'I', 'pick', 'up', 'another', 'book', 'from', 'this', 'author']\n",
      "Length_of_token: 146\n",
      "===========================================================================\n",
      "Text: I had never read this author but knew of many who did When I read that this book was being made into a movie it seemed a good opportunity to read her before seeing the screen mess up her work Now I pray that the screen does soI was extremely disappointed with this work It is unrealistic fails to capture the reader and at points when I should have been completely engrossed left me struggling with whether I wanted to pick it up I hope she has written better than this or else there are a lot of people who have not bothered reading some of the strong authors availableHer characters are not sympathetic they do not draw the readers attention and they are dull in overall scope I have too many other good books to read before I pick up another book from this author, \n",
      "Method: torchtext \n",
      "Output: ['i', 'had', 'never', 'read', 'this', 'author', 'but', 'knew', 'of', 'many', 'who', 'did', 'when', 'i', 'read', 'that', 'this', 'book', 'was', 'being', 'made', 'into', 'a', 'movie', 'it', 'seemed', 'a', 'good', 'opportunity', 'to', 'read', 'her', 'before', 'seeing', 'the', 'screen', 'mess', 'up', 'her', 'work', 'now', 'i', 'pray', 'that', 'the', 'screen', 'does', 'soi', 'was', 'extremely', 'disappointed', 'with', 'this', 'work', 'it', 'is', 'unrealistic', 'fails', 'to', 'capture', 'the', 'reader', 'and', 'at', 'points', 'when', 'i', 'should', 'have', 'been', 'completely', 'engrossed', 'left', 'me', 'struggling', 'with', 'whether', 'i', 'wanted', 'to', 'pick', 'it', 'up', 'i', 'hope', 'she', 'has', 'written', 'better', 'than', 'this', 'or', 'else', 'there', 'are', 'a', 'lot', 'of', 'people', 'who', 'have', 'not', 'bothered', 'reading', 'some', 'of', 'the', 'strong', 'authors', 'availableher', 'characters', 'are', 'not', 'sympathetic', 'they', 'do', 'not', 'draw', 'the', 'readers', 'attention', 'and', 'they', 'are', 'dull', 'in', 'overall', 'scope', 'i', 'have', 'too', 'many', 'other', 'good', 'books', 'to', 'read', 'before', 'i', 'pick', 'up', 'another', 'book', 'from', 'this', 'author']\n",
      "Length_of_token: 146\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "tokenizer_methods = ['split', 'nltk', 'spacy', 'countvector','gensim', 'torchtext']\n",
    "for meth in tokenizer_methods:\n",
    "    text = df[\"review_text\"].iloc[55]\n",
    "    tokens = tokenization(text, method=meth)\n",
    "    print(f\"Text: {text}, \\nMethod: {meth} \\nOutput: {tokens}\\nLength_of_token: {len(tokens)}\")\n",
    "    print(\"===========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e520cc80-d6cc-4293-8147-774e0dcf8ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Common vectorisation techniques/ word embeddinh(Represent words as semantically-meaningful dense real-valued vectors.)\n",
    "# 1. Count vectorization: Bag of words\n",
    "# 2. N-Grams,\n",
    "# 3. TF-IDF\n",
    "# 4. Word2Vec\n",
    "#    a. Skip Gram\n",
    "#    b. CBOW\n",
    "# 5. Glove\n",
    "# 6. FastText\n",
    "# 7. ELMO\n",
    "# 8. GPT-2\n",
    "# 9. BERT\n",
    "\n",
    "#resources: \n",
    "# https://neptune.ai/blog/word-embeddings-guide \n",
    "# https://huggingface.co/course/chapter1/1\n",
    "# https://medium.com/@dhartidhami/understanding-bert-word-embeddings-7dc4d2ea54ca\n",
    "# https://github.com/jina-ai/clip-as-service\n",
    "\n",
    "# Tensorflow Embedding space: http://projector.tensorflow.org/\n",
    "def vectorisation(text, method=\"BOW\"):\n",
    "    if method == \"BOW\":\n",
    "        cv = CountVectorizer()\n",
    "        X = cv.fit_transform(text)\n",
    "        x = X.toarray()\n",
    "        vocabs = sorted(cv.vocabulary_.keys())\n",
    "        print(\"x:\",x, \"\\nvocabs:\",vocabs)\n",
    "        return x, vocabs\n",
    "    \n",
    "    elif method == \"ngrams\":\n",
    "        cv = CountVectorizer(ngram_range=(2, 2))\n",
    "        X = cv.fit_transform(text)\n",
    "        x = X.toarray()\n",
    "        vocabs = sorted(cv.vocabulary_.keys())\n",
    "        print(\"x:\",x, \"\\nvocabs:\",vocabs)\n",
    "        return x, vocabs\n",
    "    \n",
    "    elif method == \"tfidf\":\n",
    "        tfidf = TfidfVectorizer()\n",
    "        tranformed = tfidf.fit_transform(text)\n",
    "        tfidf_dataframe = pd.DataFrame(\n",
    "            tranformed[0].T.todense(),\n",
    "            index=tfidf.get_feature_names(),\n",
    "            columns=[\"TF-IDF\"],\n",
    "        )\n",
    "        tfidf_dataframe = tfidf_dataframe.sort_values(\"TF-IDF\", ascending=False)\n",
    "        print(tfidf_dataframe)\n",
    "        return tfidf_dataframe\n",
    "    \n",
    "    elif method == \"word2vec\":\n",
    "        sentence = [sent.split() for sent in text]\n",
    "        w2v_model = models.Word2Vec(\n",
    "            sentences=sentence, vector_size=100, window=5, min_count=1, workers=7, epochs=10\n",
    "        )\n",
    "        words = [word for sent in sentence for word in sent if len(word) >= 10][:15]\n",
    "        #print(w2v_model.)\n",
    "        for wrd in words:\n",
    "            print(f\"Similar words search for : {wrd}\")\n",
    "            sim_words = w2v_model.wv.most_similar(wrd, topn=5)\n",
    "            sim_list = [wrds for wrds in sim_words]\n",
    "            print(f\"List of similar words : {sim_list}\")\n",
    "        print(f\"Words list: {words}\")\n",
    "        X = w2v_model.wv[words]\n",
    "        pca = PCA(n_components=2)\n",
    "        result = pca.fit_transform(X)\n",
    "        plt.scatter(result[:, 0], result[:, 1])\n",
    "        for i, word in enumerate(words):\n",
    "            plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "        plt.show()\n",
    "        return X\n",
    "        \n",
    "    elif method == \"glove\":\n",
    "        #error: https://stackoverflow.com/questions/66516388/attributeerror-module-torchtext-data-has-no-attribute-field\n",
    "        embed_d = {}\n",
    "        glv = glove_embed()\n",
    "        vocab_diction = dict(glv.TEXT.vocab.freqs)\n",
    "        #print(vocab_diction)\n",
    "        sentence = [sent.split() for sent in text]\n",
    "        words = {}\n",
    "        for sent in sentence:\n",
    "            sent = clean_text(sent)\n",
    "            for word in sent.split():\n",
    "                try:\n",
    "                    words[word] = vocab_diction[word]\n",
    "                except KeyError as K:\n",
    "                    print(word, \"Key error raised\")\n",
    "        print(words)\n",
    "        return words\n",
    "    \n",
    "    elif method == \"fastext\":\n",
    "        #Reference: https://thinkinfi.com/fasttext-word-embeddings-python-implementation/#:~:text=FastText%20(an%20extension%20of%20word2vec,still%20shared%20with%20other%20words.\n",
    "        tokenizer = nltk.WordPunctTokenizer()\n",
    "        word_tokens = [tokenizer.tokenize(sent) for sent in tqdm.tqdm(text)]\n",
    "        embedding_size = 300\n",
    "        window_size = 5\n",
    "        min_word = 5\n",
    "        down_sampling = 1e-2\n",
    "        \n",
    "        start = time.time()\n",
    "        fastext_model = models.FastText(word_tokens,\n",
    "                      vector_size=embedding_size,\n",
    "                      window=window_size,\n",
    "                      min_count=min_word,\n",
    "                      sample=down_sampling,\n",
    "                      workers = 6,\n",
    "                      sg=1,\n",
    "                      epochs=100)\n",
    "        end = time.time()\n",
    "        print(\"Total_time taken to train model: \",end-start)\n",
    "        \n",
    "        words_vectors = [(word, fastext_model.wv.get_vector(word)) for sent in text for word in sent.split() if len(word) >= 10][:10]\n",
    "        print(\"words_vectors: \",words_vectors)\n",
    "        return fastext_model\n",
    "    \n",
    "    elif method == \"elmo\":\n",
    "        #Reference: https://towardsdatascience.com/pytorch-elmo-844d2391a0b2,  https://guide.allennlp.org/\n",
    "        options_file = \"./embeddings/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "        weight_file = \"embeddings/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "        # Note the \"1\", since we want only 1 output representation for each token.\n",
    "        elmo = Elmo(options_file, weight_file, 1, dropout=0)\n",
    "\n",
    "        # use batch_to_ids to convert sentences to character ids\n",
    "        sentences = [['First', 'sentence', '.'], ['Another', '.']]\n",
    "        character_ids = batch_to_ids(sentences)\n",
    "\n",
    "        embeddings = elmo(character_ids)\n",
    "        print(\"Character_id: \",character_ids,\"\\nEmbedding: \",embeddings)\n",
    "        return embeddings\n",
    "    elif method == \"gpt2\":\n",
    "        #https://huggingface.co/docs/transformers/model_doc/gpt2\n",
    "        tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "        sentence = [words for sent in text for words in sent.split()]\n",
    "        embed = tokenizer(sentence)[\"input_ids\"]\n",
    "        embedding_list = [(words, embed[ind]) for ind, words in enumerate(sentence)]\n",
    "        print(embedding_list)\n",
    "        return embedding_list\n",
    "    elif method == \"bert\":\n",
    "        #reference: https://github.com/huggingface/transformers/issues/1950\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        input_ids = tokenizer.encode(text)\n",
    "        w_vector = torch.tensor(input_ids).unsqueeze(0).to(\"cuda\")\n",
    "        print(w_vector.shape, [sent.split() for sent in text], len([sent.split() for sent in text]))\n",
    "        return w_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4f605770-2646-4c41-9ecc-2b90f083e690",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3]) [['Despite', 'the', 'fact', 'that', 'I', 'have', 'only', 'played', 'a', 'small', 'portion', 'of', 'the', 'game', 'the', 'music', 'I', 'heard', 'plus', 'the', 'connection', 'to', 'Chrono', 'Trigger', 'which', 'wa', 'great', 'a', 'well', 'led', 'me', 'to', 'purchase', 'the', 'soundtrack', 'and', 'it', 'remains', 'one', 'of', 'my', 'favorite', 'album', 'There', 'is', 'an', 'incredible', 'mix', 'of', 'fun', 'epic', 'and', 'emotional', 'song', 'Those', 'sad', 'and', 'beautiful', 'track', 'I', 'especially', 'like', 'a', 'there', 'not', 'too', 'many', 'of', 'those', 'kind', 'of', 'song', 'in', 'my', 'other', 'video', 'game', 'soundtrack', 'I', 'must', 'admit', 'that', 'one', 'of', 'the', 'song', 'LifeA', 'Distant', 'Promise', 'ha', 'brought', 'tear', 'to', 'my', 'eye', 'on', 'many', 'occasion', 'My', 'one', 'complaint', 'about', 'this', 'soundtrack', 'is', 'that', 'they', 'use', 'guitar', 'fretting', 'effect', 'in', 'many', 'of', 'the', 'song', 'which', 'I', 'find', 'distracting', 'But', 'even', 'if', 'those', 'werent', 'included', 'I', 'would', 'still', 'consider', 'the', 'collection', 'worth', 'it']] 1\n",
      "embedding: tensor([[101, 100, 102]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "embed = vectorisation(df[\"review\"].iloc[:1].tolist(), method=\"bert\")\n",
    "print(\"embedding:\", embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a96432f2-c9a5-4987-8424-2a8c1e21d5d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METHOD:  BOW\n",
      "x: [[1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1\n",
      "  1 2 2 1 1 1 1 3 1 1 1 1 4 1 1 7 1 3 1 1 1 1 1 1 1 1 1 1 4 3 1 1 3 8 2 1\n",
      "  1 3 3 1 1 1 1 1 1 1 1 2 1 1]] \n",
      "vocabs: ['about', 'admit', 'album', 'an', 'and', 'beautiful', 'brought', 'but', 'chrono', 'collection', 'complaint', 'connection', 'consider', 'despite', 'distant', 'distracting', 'effect', 'emotional', 'epic', 'especially', 'even', 'eye', 'fact', 'favorite', 'find', 'fretting', 'fun', 'game', 'great', 'guitar', 'ha', 'have', 'heard', 'if', 'in', 'included', 'incredible', 'is', 'it', 'kind', 'led', 'lifea', 'like', 'many', 'me', 'mix', 'music', 'must', 'my', 'not', 'occasion', 'of', 'on', 'one', 'only', 'other', 'played', 'plus', 'portion', 'promise', 'purchase', 'remains', 'sad', 'small', 'song', 'soundtrack', 'still', 'tear', 'that', 'the', 'there', 'they', 'this', 'those', 'to', 'too', 'track', 'trigger', 'use', 'video', 'wa', 'well', 'werent', 'which', 'worth', 'would']\n",
      "Total time:  0.001332998275756836\n",
      "====================================\n",
      "METHOD:  ngrams\n",
      "x: [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 2 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1]] \n",
      "vocabs: ['about this', 'admit that', 'album there', 'an incredible', 'and beautiful', 'and emotional', 'and it', 'beautiful track', 'brought tear', 'but even', 'chrono trigger', 'collection worth', 'complaint about', 'connection to', 'consider the', 'despite the', 'distant promise', 'distracting but', 'effect in', 'emotional song', 'epic and', 'especially like', 'even if', 'eye on', 'fact that', 'favorite album', 'find distracting', 'fretting effect', 'fun epic', 'game soundtrack', 'game the', 'great well', 'guitar fretting', 'ha brought', 'have only', 'heard plus', 'if those', 'in many', 'in my', 'included would', 'incredible mix', 'is an', 'is that', 'it remains', 'kind of', 'led me', 'lifea distant', 'like there', 'many occasion', 'many of', 'me to', 'mix of', 'music heard', 'must admit', 'my eye', 'my favorite', 'my one', 'my other', 'not too', 'occasion my', 'of fun', 'of my', 'of song', 'of the', 'of those', 'on many', 'one complaint', 'one of', 'only played', 'other video', 'played small', 'plus the', 'portion of', 'promise ha', 'purchase the', 'remains one', 'sad and', 'small portion', 'song in', 'song lifea', 'song those', 'song which', 'soundtrack and', 'soundtrack is', 'soundtrack must', 'still consider', 'tear to', 'that have', 'that one', 'that they', 'the collection', 'the connection', 'the fact', 'the game', 'the music', 'the song', 'the soundtrack', 'there is', 'there not', 'they use', 'this soundtrack', 'those kind', 'those sad', 'those werent', 'to chrono', 'to my', 'to purchase', 'too many', 'track especially', 'trigger which', 'use guitar', 'video game', 'wa great', 'well led', 'werent included', 'which find', 'which wa', 'worth it', 'would still']\n",
      "Total time:  0.000989675521850586\n",
      "====================================\n",
      "METHOD:  tfidf\n",
      "            TF-IDF\n",
      "the       0.461112\n",
      "of        0.403473\n",
      "my        0.230556\n",
      "song      0.230556\n",
      "many      0.172917\n",
      "...            ...\n",
      "great     0.057639\n",
      "fun       0.057639\n",
      "fretting  0.057639\n",
      "find      0.057639\n",
      "would     0.057639\n",
      "\n",
      "[86 rows x 1 columns]\n",
      "Total time:  0.0035817623138427734\n",
      "====================================\n",
      "METHOD:  word2vec\n",
      "Similar words search for : connection\n",
      "List of similar words : [('small', 0.261943519115448), ('There', 0.26136690378189087), ('incredible', 0.223286435008049), ('led', 0.18716655671596527), ('admit', 0.14447021484375)]\n",
      "Similar words search for : soundtrack\n",
      "List of similar words : [('music', 0.3527142107486725), ('great', 0.30746227502822876), ('sad', 0.2527462840080261), ('track', 0.22627796232700348), ('epic', 0.1772141456604004)]\n",
      "Similar words search for : incredible\n",
      "List of similar words : [('connection', 0.22328642010688782), ('ha', 0.18062549829483032), ('game', 0.1724517047405243), ('fretting', 0.16504767537117004), ('album', 0.15689808130264282)]\n",
      "Similar words search for : especially\n",
      "List of similar words : [('favorite', 0.18460023403167725), ('that', 0.15386413037776947), ('find', 0.1492457389831543), ('incredible', 0.14605848491191864), ('too', 0.1368238627910614)]\n",
      "Similar words search for : soundtrack\n",
      "List of similar words : [('music', 0.3527142107486725), ('great', 0.30746227502822876), ('sad', 0.2527462840080261), ('track', 0.22627796232700348), ('epic', 0.1772141456604004)]\n",
      "Similar words search for : soundtrack\n",
      "List of similar words : [('music', 0.3527142107486725), ('great', 0.30746227502822876), ('sad', 0.2527462840080261), ('track', 0.22627796232700348), ('epic', 0.1772141456604004)]\n",
      "Similar words search for : distracting\n",
      "List of similar words : [('There', 0.25515273213386536), ('emotional', 0.19980092346668243), ('game', 0.19914479553699493), ('to', 0.16512981057167053), ('My', 0.1500691920518875)]\n",
      "Similar words search for : collection\n",
      "List of similar words : [('emotional', 0.23425893485546112), ('must', 0.20005957782268524), ('beautiful', 0.18990878760814667), ('occasion', 0.18067577481269836), ('those', 0.14849425852298737)]\n",
      "Words list: ['connection', 'soundtrack', 'incredible', 'especially', 'soundtrack', 'soundtrack', 'distracting', 'collection']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:  0.12409114837646484\n",
      "====================================\n",
      "METHOD:  glove\n",
      "Length of TRAIN_data: 8000,Length of TEST_data: 4000 \n",
      "Unique tokens in :\n",
      "TEXT vocab:4531,\n",
      "LABEL vocab:2\n",
      "Label vocab_freq: Counter({'2': 4079, '1': 3921})\n",
      "wa Key error raised\n",
      "LifeA Key error raised\n",
      "werent Key error raised\n",
      "{'Despite': 20, 'the': 27103, 'fact': 237, 'that': 6511, 'I': 16618, 'have': 3912, 'only': 1324, 'played': 140, 'a': 14755, 'small': 255, 'portion': 11, 'of': 12832, 'game': 245, 'music': 639, 'heard': 221, 'plus': 56, 'connection': 50, 'to': 14660, 'Chrono': 1, 'Trigger': 2, 'which': 903, 'great': 1573, 'well': 985, 'led': 25, 'me': 1660, 'purchase': 193, 'soundtrack': 65, 'and': 16414, 'it': 11030, 'remains': 23, 'one': 2734, 'my': 2986, 'favorite': 229, 'album': 654, 'There': 514, 'is': 11395, 'an': 1753, 'incredible': 53, 'mix': 46, 'fun': 258, 'epic': 30, 'emotional': 36, 'song': 340, 'Those': 22, 'sad': 97, 'beautiful': 144, 'track': 117, 'especially': 193, 'like': 2180, 'there': 1165, 'not': 3934, 'too': 860, 'many': 777, 'those': 432, 'kind': 187, 'in': 7208, 'other': 1034, 'video': 229, 'must': 389, 'admit': 46, 'Distant': 1, 'Promise': 2, 'ha': 2, 'brought': 66, 'tear': 17, 'eye': 33, 'on': 4140, 'occasion': 6, 'My': 553, 'complaint': 37, 'about': 1802, 'this': 9035, 'they': 1852, 'use': 585, 'guitar': 48, 'fretting': 1, 'effect': 32, 'find': 575, 'distracting': 20, 'But': 582, 'even': 997, 'if': 1416, 'included': 77, 'would': 1841, 'still': 584, 'consider': 60, 'collection': 175, 'worth': 421}\n",
      "Total time:  4.59459924697876\n",
      "====================================\n",
      "METHOD:  fastext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 13706.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_time taken to train model:  2.327190637588501\n",
      "words_vectors:  [('connection', array([ 2.40453719e-05,  1.75593945e-04,  4.93522850e-04, -4.86008765e-04,\n",
      "       -9.40322425e-05,  3.64242325e-04, -5.41732705e-04,  1.21480596e-04,\n",
      "       -2.86420051e-04,  8.18315195e-04,  7.38360861e-04,  8.80507869e-05,\n",
      "       -2.11404855e-04, -2.69254315e-07,  3.26417881e-04,  1.92177060e-04,\n",
      "        1.43540092e-04, -4.08549036e-04,  4.49835992e-04, -2.90448486e-04,\n",
      "        3.06705246e-04,  4.96631139e-04,  2.59523513e-05, -3.01713590e-04,\n",
      "        2.57560478e-05,  8.44544847e-05, -4.24579002e-06,  3.21717205e-04,\n",
      "        7.12735200e-05,  1.76645626e-04, -8.11148711e-05, -3.47809895e-04,\n",
      "       -5.28002798e-04,  2.62162648e-04, -3.66770400e-04,  2.16364322e-04,\n",
      "        4.33875044e-04, -7.09755986e-05, -9.78727592e-04, -1.65782752e-04,\n",
      "        2.83704518e-04,  8.21952417e-05,  4.32192581e-04, -3.58485064e-04,\n",
      "        4.29003616e-04,  9.96982544e-06, -9.90593107e-05, -3.01892112e-04,\n",
      "       -9.41151666e-05,  3.06606409e-04,  5.28756063e-05,  2.55825697e-04,\n",
      "        2.17358058e-04, -2.36527558e-04, -2.75104190e-04, -4.46166450e-05,\n",
      "       -3.90241294e-05,  6.40529397e-05, -5.44080976e-04, -6.02516055e-04,\n",
      "        4.98347450e-04,  1.84581557e-04,  5.80046944e-05, -1.78738934e-04,\n",
      "       -4.84860066e-04,  6.54003117e-04, -7.52042833e-05, -1.10581575e-04,\n",
      "        1.45970203e-04,  5.95696853e-04, -9.01824169e-05, -1.66710277e-04,\n",
      "        1.07369924e-04,  3.92141956e-04,  2.23270181e-05,  2.20183283e-04,\n",
      "       -1.91496700e-04,  2.49800705e-05, -7.67174060e-05,  3.64171254e-04,\n",
      "       -1.88652732e-04,  3.21577128e-04, -8.49111646e-04, -6.39424368e-04,\n",
      "       -4.37238603e-04,  2.38707100e-04,  6.20167630e-05,  2.68234202e-04,\n",
      "       -1.05776577e-04, -1.54923793e-04,  3.39527935e-04,  1.99027942e-04,\n",
      "        4.04591730e-04,  7.39435432e-04,  6.16270816e-04, -1.19372999e-04,\n",
      "       -5.19074791e-04,  9.31928516e-05, -4.59983276e-04,  2.39401779e-04,\n",
      "       -2.60053115e-04, -8.12028084e-05,  4.03389626e-04,  7.47512793e-04,\n",
      "       -7.88790348e-05, -2.32211751e-04, -5.76089020e-04,  3.05603084e-04,\n",
      "        7.70610932e-04, -2.88822077e-04, -5.35984931e-04,  4.32449975e-04,\n",
      "        2.20212183e-04,  5.22529626e-05,  1.44814199e-04,  2.03214746e-04,\n",
      "        3.80156649e-04,  7.30715183e-05, -1.47503568e-04, -4.46572049e-05,\n",
      "       -6.53161405e-05, -1.06763437e-04, -9.83030535e-04, -8.00880080e-04,\n",
      "        3.60247737e-04, -2.74129969e-04,  4.92631749e-04, -4.65642923e-04,\n",
      "       -3.33712203e-04, -1.12111062e-04,  3.05041933e-04, -1.87854646e-04,\n",
      "        2.43101051e-04,  3.36050522e-04,  6.43760432e-04,  2.18106543e-05,\n",
      "        1.75230118e-04, -8.59832217e-05, -1.36729475e-04,  2.15741733e-04,\n",
      "       -4.95455810e-04,  2.32977516e-04, -2.05615623e-04, -6.74043957e-04,\n",
      "       -1.31326538e-04, -4.62641678e-04, -4.85556338e-05,  1.86350386e-04,\n",
      "       -5.64985894e-05, -2.87440605e-04,  4.33434092e-04,  8.93520773e-05,\n",
      "       -5.02761919e-04, -3.00357526e-04, -5.71814599e-04, -6.43342792e-05,\n",
      "        5.44923707e-04,  3.87329987e-04, -1.83838987e-04,  4.97614383e-06,\n",
      "       -9.96773961e-05, -5.24395669e-04, -9.31922659e-06, -1.33623180e-04,\n",
      "       -2.99045874e-04,  2.76068604e-05,  2.33915285e-04,  1.25050210e-04,\n",
      "        3.67907807e-04, -1.80943243e-04, -5.23054216e-04, -1.31307053e-04,\n",
      "        3.55162862e-04, -1.41733952e-04,  2.96996237e-04, -2.09052523e-04,\n",
      "        5.18101791e-04, -1.37929819e-04, -3.51376482e-04, -2.41907779e-04,\n",
      "       -5.39695262e-04,  2.23251554e-04,  1.51270913e-04, -2.11171384e-04,\n",
      "       -4.83051699e-04,  1.10037392e-04,  7.61409028e-05, -2.92065641e-04,\n",
      "       -2.38524401e-04,  3.32247262e-04,  5.54109458e-04, -1.05402651e-04,\n",
      "       -7.58000606e-05, -5.93712670e-04, -1.39387674e-04,  9.16424979e-05,\n",
      "        4.21531673e-04, -5.19946043e-04, -3.78112920e-04, -2.60577770e-04,\n",
      "       -2.68397183e-04,  2.17095570e-04, -1.86383098e-04, -2.06756260e-04,\n",
      "       -1.42314784e-05,  4.30318236e-04,  3.71930182e-05, -4.54900030e-04,\n",
      "       -4.89778431e-05, -8.67492490e-05, -2.20797461e-04,  5.08974714e-04,\n",
      "        4.89064550e-04,  2.54652958e-04, -5.15221909e-04, -1.22514262e-04,\n",
      "       -2.95856589e-04,  1.07998982e-04,  3.17880731e-05,  2.37402128e-04,\n",
      "       -1.10815970e-04,  2.87499221e-04, -2.03429852e-04,  7.48836726e-04,\n",
      "        5.10266749e-04, -2.56472937e-04, -3.26557754e-04, -1.43405661e-04,\n",
      "        1.01408317e-04,  1.63134449e-04, -2.35221014e-04,  8.00151101e-05,\n",
      "       -4.54457244e-04, -5.94970079e-05,  5.58112341e-04,  4.09045169e-05,\n",
      "        2.58544576e-04,  2.61407229e-04, -3.24645400e-04, -3.53750132e-04,\n",
      "       -6.10564020e-05, -4.17883421e-05,  8.78620849e-05,  4.56168898e-04,\n",
      "       -3.93688009e-04,  3.19743296e-04, -1.84298449e-04, -4.77984286e-04,\n",
      "        9.02860029e-06,  3.55749595e-04,  2.47287971e-04, -1.50281980e-04,\n",
      "        2.75842904e-04,  2.24252813e-04,  4.01581783e-04,  1.90588427e-04,\n",
      "        1.59016490e-04,  8.20814603e-05, -1.59389412e-04, -3.10765085e-04,\n",
      "        8.70745644e-05, -1.02434700e-04,  3.14658158e-04, -4.30124172e-04,\n",
      "       -2.74052174e-04, -1.28954862e-05, -3.06936156e-04,  1.03007835e-04,\n",
      "       -1.52507564e-04,  3.73253279e-04, -2.19904359e-05,  6.24878216e-04,\n",
      "        1.29959561e-04,  6.35688659e-04,  2.14883810e-04, -2.59511842e-04,\n",
      "        9.69190733e-05, -1.86535777e-04,  2.01975505e-04,  3.82490223e-04,\n",
      "       -5.95795515e-04,  2.34070118e-04,  4.55358895e-05,  3.18566337e-04,\n",
      "       -7.32993649e-04, -3.08789313e-04, -1.98653550e-04,  8.16178945e-05,\n",
      "       -5.46094816e-05, -7.59184331e-05, -2.66018644e-04,  1.58210722e-04,\n",
      "       -6.58697099e-05, -2.12223284e-04, -3.35737714e-05,  2.80468812e-05,\n",
      "        4.79245027e-05, -6.49592548e-05, -2.59914726e-04,  6.12649965e-05],\n",
      "      dtype=float32)), ('soundtrack', array([-2.42948772e-05,  4.27131308e-04,  5.91629883e-04,  5.20400237e-04,\n",
      "       -9.90404951e-05, -4.91452956e-05, -8.53989040e-05, -1.85289115e-04,\n",
      "       -8.25427924e-05, -1.23755817e-04,  3.68062494e-04, -5.39230765e-04,\n",
      "       -5.13935112e-04, -5.89534175e-05, -2.27226352e-04, -3.24139372e-04,\n",
      "        4.44806414e-04,  2.45883362e-04,  8.50350916e-05, -2.60988250e-04,\n",
      "        1.79053590e-04,  2.41960675e-04, -1.27123581e-04,  4.34044458e-04,\n",
      "        1.38322386e-04, -1.68419152e-04, -8.67033668e-05, -3.87892906e-05,\n",
      "       -2.47420976e-04, -1.42678429e-04,  9.24715539e-04, -1.10788795e-04,\n",
      "        4.30473592e-04, -1.42084187e-04,  5.41166577e-04, -8.00249167e-04,\n",
      "       -3.89736029e-04,  2.97279359e-04,  2.01256014e-04,  2.09089936e-04,\n",
      "       -1.43792829e-04,  1.84066375e-04,  4.84442076e-04, -1.99878035e-04,\n",
      "       -6.96168863e-05,  3.99155193e-04, -1.14965675e-04, -1.13392116e-06,\n",
      "        3.64152365e-04,  3.54417978e-04, -2.59668828e-04,  5.39321627e-05,\n",
      "        3.98300530e-04,  1.78806056e-06, -3.39695616e-05,  4.74614964e-04,\n",
      "       -6.11950527e-05, -1.97660993e-04,  1.78616159e-04, -4.40378280e-05,\n",
      "       -3.61509068e-04, -2.62650457e-04, -4.48333703e-05,  9.08120710e-05,\n",
      "        1.18541345e-03, -7.29612657e-05, -2.42301510e-04, -1.63112727e-05,\n",
      "       -9.20770399e-05,  6.63282350e-04, -2.52454018e-04,  1.01474288e-04,\n",
      "        1.47654850e-04,  1.07709697e-04,  2.49499251e-04, -1.42847275e-04,\n",
      "       -4.97611254e-05,  4.86314617e-04, -5.45393385e-04,  2.13527936e-04,\n",
      "        1.13704746e-05,  3.61491402e-04, -1.48241597e-04, -2.07056321e-04,\n",
      "        4.25845385e-04, -5.79870190e-04,  2.67255618e-05, -1.95639994e-04,\n",
      "       -5.09472506e-04,  2.99931125e-04,  3.03242541e-05,  2.06639597e-04,\n",
      "        8.75952537e-05, -4.12880850e-04, -2.13295298e-05, -2.52946047e-04,\n",
      "        1.07092274e-04, -3.48259491e-04, -7.60389303e-05,  5.04017691e-04,\n",
      "        1.35035916e-05, -2.47820426e-05,  5.54421058e-05, -5.49108023e-04,\n",
      "       -1.19769375e-05,  4.73825930e-04, -2.32789331e-04,  1.25041537e-04,\n",
      "       -2.01519055e-04,  1.55934977e-04,  3.81439051e-04,  1.67659542e-04,\n",
      "        1.11181274e-04, -9.12570904e-05, -2.57652835e-04, -4.45329322e-04,\n",
      "        3.30779003e-04, -9.83565551e-05,  3.57465586e-04,  4.87039244e-04,\n",
      "        2.50787270e-04,  3.19803541e-04,  2.83763547e-05, -5.27040451e-04,\n",
      "       -4.94235603e-04,  5.65856404e-04,  2.90585624e-04,  7.30025116e-04,\n",
      "       -2.06443394e-04,  3.75237723e-05,  2.58567627e-04,  1.99112983e-04,\n",
      "        3.58113728e-04,  3.99629265e-04,  4.57493705e-04,  2.79076543e-04,\n",
      "       -2.37801825e-04,  5.28138655e-04,  4.82422620e-04,  3.10286268e-04,\n",
      "       -3.08615330e-04,  1.58987896e-05, -5.69302356e-04, -3.32409400e-04,\n",
      "       -3.70616544e-05,  1.08855966e-04, -1.34085785e-04, -1.18397329e-04,\n",
      "       -1.40460455e-04, -4.83957556e-04, -1.43544414e-04, -4.69123013e-04,\n",
      "       -1.39942524e-04, -1.59559553e-04,  3.13013268e-04,  1.76126443e-04,\n",
      "        4.45940939e-04, -1.32885079e-05, -3.13124387e-04, -4.90636856e-04,\n",
      "        1.16461131e-04, -3.17507714e-04,  2.38176712e-04,  8.19495908e-05,\n",
      "        5.92700497e-04, -1.60735915e-04,  1.85153869e-04, -2.36865351e-04,\n",
      "       -3.30760173e-04, -1.08792540e-03,  1.50742169e-04, -6.68248540e-05,\n",
      "       -2.83354660e-04,  3.68797511e-04,  1.31376553e-04, -4.60762414e-04,\n",
      "        5.62202222e-05, -5.94351848e-04, -6.58058096e-04, -7.89783226e-05,\n",
      "       -5.16154629e-04,  3.90787260e-04,  2.79939850e-04,  4.50454594e-04,\n",
      "       -3.38624872e-04, -2.92478013e-04,  3.13705066e-04, -1.48124222e-04,\n",
      "        1.04724793e-04, -2.44567404e-04,  4.32643137e-05, -6.07267197e-04,\n",
      "        8.54912505e-05,  8.50141223e-05,  2.18662666e-04,  4.13705166e-05,\n",
      "       -6.23639557e-04, -7.07578656e-05, -8.69652358e-05, -4.85751989e-05,\n",
      "       -2.63529982e-05,  4.78650705e-04, -5.91226446e-04,  5.12918981e-04,\n",
      "       -3.37826816e-04,  3.01395950e-04, -2.32455404e-05,  1.36112387e-04,\n",
      "       -3.94518342e-04,  4.55581139e-05, -3.15578538e-04,  1.84660399e-04,\n",
      "       -1.88409205e-04, -2.11761526e-05,  1.15283518e-04,  1.37956260e-04,\n",
      "       -6.12288364e-04, -2.74636637e-04,  2.01514398e-04, -2.68472271e-04,\n",
      "       -4.33624344e-04,  9.66606749e-05,  1.55160800e-04,  8.38958076e-05,\n",
      "        3.28624126e-04, -9.16129866e-05, -8.32536956e-04, -4.48261089e-05,\n",
      "        5.54585131e-06,  1.66768557e-04,  2.00634386e-04, -5.94480334e-05,\n",
      "        3.91644513e-04, -1.62714437e-04,  2.05885008e-04,  2.64683826e-04,\n",
      "        2.48514494e-04,  2.06891898e-04, -4.72903812e-05, -1.27179082e-04,\n",
      "       -2.15011532e-04, -1.98627706e-04,  7.15582224e-04,  2.25617009e-06,\n",
      "        7.45883517e-05, -4.49912390e-04, -4.17996489e-05,  5.15532156e-05,\n",
      "        7.60165218e-04,  7.00792443e-05,  1.65314792e-04,  1.58166396e-04,\n",
      "        6.43276362e-05, -1.74156652e-04, -1.80740040e-04, -3.74411495e-04,\n",
      "       -4.68951257e-05,  7.67728197e-05, -2.34535895e-04, -1.16573926e-03,\n",
      "        3.55010452e-05, -5.23224007e-04,  3.35280856e-05,  2.70821241e-04,\n",
      "       -3.36129946e-04, -1.98860900e-04,  2.67279393e-04, -8.49178032e-05,\n",
      "        4.79303621e-04,  9.66412263e-05, -1.16521631e-04, -6.58625271e-04,\n",
      "        2.36363539e-05, -1.71020627e-04, -4.30313929e-04,  8.73453449e-04,\n",
      "        2.44447321e-04,  1.78962364e-04,  5.27656055e-04, -3.26781097e-04,\n",
      "       -2.11880797e-05,  1.41555822e-04, -3.23631306e-04,  1.49299391e-04,\n",
      "        2.19269336e-04,  5.76265738e-04, -7.47240847e-04, -3.10610689e-04,\n",
      "        5.60020599e-05,  2.85324524e-04, -2.24637959e-04, -4.01811303e-05,\n",
      "        1.78822782e-04, -6.27846457e-04,  3.13054596e-04,  8.21751455e-05,\n",
      "        1.94545610e-05, -2.10262559e-04,  2.62687041e-04, -5.87538489e-05],\n",
      "      dtype=float32)), ('incredible', array([ 4.32901754e-04,  4.93566622e-04,  1.23942795e-04, -3.63178842e-04,\n",
      "       -7.34169967e-04, -8.39960412e-05, -1.92157313e-04, -6.98929216e-05,\n",
      "       -4.95800032e-06,  4.31459543e-04, -1.68268132e-04, -1.29172595e-05,\n",
      "       -5.31643163e-04,  6.81494770e-04,  2.64959235e-04,  5.86055918e-04,\n",
      "        4.96699242e-04,  2.44857336e-04, -1.59397779e-04, -1.38481089e-04,\n",
      "        4.00087039e-04, -2.28474382e-05, -3.75141390e-04,  1.30839457e-04,\n",
      "        2.45292613e-04,  3.42731422e-04, -5.47253236e-04,  2.11934166e-04,\n",
      "       -4.41325596e-04,  1.77234222e-04,  2.04338183e-04, -2.08364523e-04,\n",
      "        6.55797267e-05, -5.14174579e-04, -6.15586978e-05,  7.93734449e-04,\n",
      "        3.70705064e-04, -3.56775679e-04, -5.23858878e-04,  1.57989969e-04,\n",
      "        3.22145155e-07, -2.79731350e-04,  4.04618564e-04, -6.16257676e-05,\n",
      "       -1.28155691e-04, -1.69685081e-04, -3.45056062e-04, -4.67099017e-04,\n",
      "       -1.32418078e-04,  1.65855425e-04, -2.51241843e-04, -4.33899229e-04,\n",
      "        8.70625991e-06,  2.95931386e-04, -2.63825728e-04,  4.55766567e-04,\n",
      "        4.17640636e-04, -2.96671002e-04, -8.69491632e-05,  1.44682243e-04,\n",
      "        4.05917788e-04,  2.63780181e-04, -4.47664614e-04,  6.21587504e-04,\n",
      "       -8.86424641e-06, -3.72430834e-04, -3.43522028e-04,  4.20307304e-04,\n",
      "       -5.91171811e-05,  2.70412187e-04, -1.83486293e-06,  1.33286776e-05,\n",
      "        2.03805379e-04, -3.83483188e-04, -3.36950412e-04,  5.21821821e-05,\n",
      "        3.20618565e-04,  2.49382341e-04,  1.30187604e-04, -1.21391102e-04,\n",
      "       -2.61408975e-04, -4.67168778e-04,  3.80655052e-04,  1.77437556e-04,\n",
      "        1.92537100e-05, -2.51936890e-05,  2.67463038e-04, -1.07829590e-04,\n",
      "        1.13060247e-04, -2.77657789e-04,  5.32628619e-04,  4.90436971e-04,\n",
      "       -3.87645268e-04,  6.66968408e-04,  3.49125679e-04,  4.84509656e-04,\n",
      "       -9.07917856e-05, -2.68997857e-04, -1.74119094e-04,  1.31515510e-04,\n",
      "        4.38513205e-04,  3.22749489e-04, -6.66485867e-04,  1.62329161e-04,\n",
      "        3.88997811e-04,  2.52539670e-04, -2.74668273e-04,  5.73174562e-04,\n",
      "        4.41433396e-04,  3.26965761e-04, -1.66000245e-04, -6.09248418e-05,\n",
      "        1.38708419e-04, -3.85592313e-04, -1.22553232e-04, -5.18749701e-04,\n",
      "       -1.42510093e-04,  6.76362542e-04,  4.35559195e-04, -4.38584597e-04,\n",
      "        1.92402716e-04,  5.21984417e-04,  6.85370178e-05, -1.83673736e-04,\n",
      "       -3.55005614e-04,  4.05207480e-04, -2.97993847e-05,  4.76388741e-05,\n",
      "        1.23634854e-05,  9.49488167e-05,  1.49695916e-04,  1.12346323e-04,\n",
      "        5.68990712e-04, -2.33076076e-04, -7.51253625e-04, -2.12802202e-04,\n",
      "        9.03682740e-05, -1.52149703e-04,  1.74358822e-04, -2.78995896e-04,\n",
      "        4.56120208e-04, -5.27012162e-06, -6.15259924e-04, -1.34018381e-04,\n",
      "       -1.95852423e-04,  4.04708699e-05, -2.70005345e-04,  1.49709362e-04,\n",
      "        2.03167201e-05,  3.15573474e-04, -1.17386866e-04,  2.66240950e-05,\n",
      "        1.99216738e-05, -1.33375113e-04, -3.54311080e-04, -2.74947870e-05,\n",
      "        1.45564845e-04, -4.53893532e-04,  6.97217649e-04,  2.25089083e-04,\n",
      "        1.48023828e-04, -8.39567656e-05,  2.00839990e-04,  5.48361350e-05,\n",
      "       -4.38696996e-04,  3.31561838e-04, -1.82173069e-04,  2.13858402e-05,\n",
      "       -3.40900995e-04,  2.10233251e-04, -4.24661121e-04,  2.22505943e-04,\n",
      "       -2.32732171e-04, -1.30392771e-04,  1.24816317e-04,  2.54961633e-04,\n",
      "       -4.35058377e-04, -8.68561547e-05,  1.08725872e-04,  1.46915787e-04,\n",
      "        2.14514206e-04, -1.88707287e-04,  3.84252053e-04,  5.91551652e-04,\n",
      "        9.86229861e-04, -1.25158622e-04, -5.42421592e-04, -1.68927450e-04,\n",
      "       -7.10913097e-04, -9.18945952e-05, -3.06646543e-04,  3.11274256e-04,\n",
      "       -1.49315398e-04,  2.87061048e-05, -4.54120775e-04,  4.76914342e-04,\n",
      "       -2.59300432e-04,  2.93179455e-05, -1.74245957e-04,  2.41521338e-04,\n",
      "        3.88381188e-04, -3.82088241e-04, -3.30173643e-04, -4.84251796e-04,\n",
      "       -4.89661143e-05,  6.17610931e-05,  1.90384999e-05,  1.96331282e-04,\n",
      "       -7.74090353e-04,  6.50218717e-05,  2.38249486e-04,  3.53531766e-04,\n",
      "        1.91183863e-04,  6.21154322e-05,  1.29012828e-04,  1.62828976e-04,\n",
      "        2.01569255e-05,  9.40596510e-05, -2.38397028e-04,  3.42683808e-04,\n",
      "        1.96332781e-04, -1.85062861e-04,  9.20090897e-05, -5.67177252e-04,\n",
      "        7.53492859e-05, -3.85437888e-04,  2.37106462e-04, -2.55748218e-05,\n",
      "        3.97792581e-04,  7.07095605e-04, -3.12458258e-04,  6.30392868e-04,\n",
      "        1.64750061e-04,  4.98111942e-04,  2.62309244e-04,  1.60400905e-05,\n",
      "       -3.89668639e-05,  3.31346761e-04, -3.00180458e-04,  5.19889931e-04,\n",
      "       -4.06268227e-05, -8.17517430e-05,  1.79307186e-04,  1.82512071e-04,\n",
      "       -4.36049595e-04,  2.65380833e-04, -6.80721307e-04, -9.91409179e-04,\n",
      "       -4.35123104e-04,  3.69774643e-05, -4.12052730e-04,  4.18042124e-04,\n",
      "        1.95090906e-04, -5.06610028e-04, -5.13951352e-04, -1.46379942e-04,\n",
      "       -5.37759683e-04,  3.81907448e-04, -8.19126217e-05,  1.40151576e-04,\n",
      "        5.71940502e-04,  2.78211926e-04, -6.80599362e-04,  7.99871399e-04,\n",
      "       -1.47505722e-04, -4.38217161e-04, -5.63876878e-04, -1.28899745e-04,\n",
      "       -6.87997672e-05,  1.73309541e-04, -1.53812842e-04, -3.22876599e-06,\n",
      "        6.31549119e-05,  2.67750409e-04,  6.24178792e-04,  2.11473860e-04,\n",
      "       -4.53094952e-04, -5.39291534e-04,  2.53362523e-04,  3.65552842e-04,\n",
      "        3.47729831e-04, -4.61333431e-04,  6.85544452e-04, -6.07664464e-04,\n",
      "       -1.34351634e-04, -1.25136095e-04,  6.24679553e-04,  4.99844784e-04,\n",
      "        7.46422913e-04,  2.12927262e-04,  3.55405034e-04, -1.11980393e-04,\n",
      "       -2.75770115e-04,  1.73496242e-04,  2.20951712e-04, -5.42635506e-04,\n",
      "        8.06415279e-04,  5.01190370e-04, -2.37244894e-04, -2.37401488e-04],\n",
      "      dtype=float32)), ('especially', array([ 2.94883474e-04,  3.71748320e-04, -1.79935581e-04,  4.17331830e-06,\n",
      "        9.21642495e-05,  3.53262949e-05, -5.21767361e-04, -3.69867135e-04,\n",
      "        5.90584168e-05, -2.30268168e-04, -3.55896532e-06, -8.47128918e-04,\n",
      "        2.56210915e-05, -3.04746616e-04,  2.10440776e-04, -4.45095997e-04,\n",
      "       -2.54092942e-04,  7.34573870e-04, -4.02450183e-04,  1.79920316e-05,\n",
      "        1.36869654e-04, -1.13877177e-04,  2.41918737e-04,  6.71991613e-04,\n",
      "       -1.05136533e-04,  1.65645062e-04,  2.70050532e-05, -1.90923442e-04,\n",
      "       -2.39658286e-04,  2.93258025e-04, -5.77381579e-04, -1.14796258e-05,\n",
      "        4.98489942e-04, -2.23878465e-04,  1.04360652e-05, -2.63363589e-04,\n",
      "        6.84039551e-04, -2.98441650e-04,  2.20555667e-04, -3.74756601e-05,\n",
      "       -1.30081302e-04, -1.40794888e-04, -2.16501183e-04, -4.67663573e-04,\n",
      "       -3.39078542e-05, -6.59869038e-05, -3.79861216e-04,  3.49664449e-04,\n",
      "        2.04795884e-04, -6.64236068e-05,  5.79931548e-05,  3.21771222e-04,\n",
      "        1.66432219e-04,  3.21783242e-04,  4.02399572e-04, -1.74803572e-05,\n",
      "       -1.61574135e-04, -3.22143082e-04, -3.78627708e-04, -1.47547718e-04,\n",
      "        2.81998393e-04,  2.07683755e-04, -4.95299946e-06, -4.79708164e-04,\n",
      "       -4.49009713e-05, -9.01548250e-04, -4.23732883e-04, -2.33704341e-05,\n",
      "       -3.85806547e-04, -5.92900789e-04,  2.52373691e-04,  9.10565723e-04,\n",
      "       -2.70630961e-04, -6.30435825e-05, -6.84104816e-05, -2.36795880e-04,\n",
      "        2.96632119e-04,  4.08072548e-04, -1.71386899e-04, -1.89862221e-05,\n",
      "       -4.25635604e-04,  1.64541838e-04, -1.25768231e-04,  4.76258865e-04,\n",
      "        9.16132121e-05,  1.63858072e-04, -2.01827308e-04,  2.54456623e-04,\n",
      "        6.74270384e-04,  1.00869787e-04, -3.34507640e-04, -9.45765059e-05,\n",
      "       -1.04416358e-04,  4.38053277e-04,  5.84986446e-05, -1.31085399e-04,\n",
      "        1.86675737e-04,  1.10577348e-04,  5.89365605e-04,  3.20734456e-04,\n",
      "       -3.02835106e-04,  6.17447600e-04, -2.15290274e-04,  3.86371510e-04,\n",
      "        1.92694788e-04, -1.07592983e-04, -7.64806919e-06, -1.24004917e-04,\n",
      "       -6.35615899e-04,  9.89443579e-05, -3.53653420e-04, -4.38302322e-06,\n",
      "       -3.87050895e-05, -2.51546851e-04,  3.27995622e-05, -3.19915358e-04,\n",
      "       -6.58036268e-04, -2.89077900e-04,  1.38006129e-04,  2.22634219e-04,\n",
      "        5.36179636e-04, -6.87487118e-05, -1.28074549e-04, -1.96153647e-04,\n",
      "       -4.30251763e-04,  1.47911342e-04, -9.84070575e-05,  6.03806460e-04,\n",
      "        4.04352322e-04,  1.04927858e-04,  3.17788596e-04,  1.51496031e-04,\n",
      "       -1.51789591e-05, -4.21246696e-05,  5.13816776e-04, -3.71833448e-04,\n",
      "       -2.29476227e-05, -5.21628863e-05,  1.75998619e-04,  6.81838792e-05,\n",
      "        6.56295335e-04,  2.61580979e-04,  4.86116740e-04,  2.45605042e-04,\n",
      "       -1.89482758e-04,  2.77483996e-05, -2.89571413e-04,  3.66453780e-04,\n",
      "        8.02301802e-04,  1.44363483e-04, -7.40903924e-05, -8.86254638e-05,\n",
      "       -2.40784953e-04, -1.82138858e-04, -5.16551896e-04,  2.99558771e-04,\n",
      "       -1.91831612e-04, -4.65880468e-04,  2.11167353e-04,  3.22284468e-04,\n",
      "       -3.33191885e-04, -3.00588872e-04,  2.93975958e-04,  5.94407960e-04,\n",
      "        3.93281778e-04,  2.56607134e-04,  2.76669190e-04, -3.31811199e-04,\n",
      "        3.59191545e-05,  1.41282699e-05, -1.70839980e-04,  4.98327950e-04,\n",
      "       -2.85616552e-04, -2.23027644e-04, -5.89684132e-05,  5.12098952e-04,\n",
      "       -8.48580166e-05,  9.92174955e-06, -3.23495100e-04, -2.08325568e-04,\n",
      "        4.22020938e-04, -1.28769179e-05, -3.70343478e-04,  6.42346422e-05,\n",
      "       -7.70737010e-04, -6.11458090e-05, -1.97379104e-05, -3.91514041e-05,\n",
      "       -6.62454113e-04, -2.77576444e-04, -4.46981518e-04,  3.30771465e-04,\n",
      "       -1.41533237e-04, -2.35298678e-04,  5.08637633e-04, -6.46601664e-04,\n",
      "       -3.97486292e-04, -4.50243278e-05,  3.21147003e-04,  3.76375538e-05,\n",
      "       -1.72890883e-04,  1.13855764e-04,  4.09220404e-04, -1.83540196e-05,\n",
      "       -9.17795296e-06,  4.29520514e-06, -1.08108914e-04, -5.69030177e-04,\n",
      "        2.01582603e-04, -4.41518059e-04,  2.10509053e-04, -1.12274874e-05,\n",
      "        8.93947508e-05, -1.59753035e-05, -4.67112950e-05, -1.98437643e-04,\n",
      "        3.57434415e-04,  4.59767063e-04,  9.04383138e-04, -5.20084905e-05,\n",
      "       -5.32565027e-05, -1.08323919e-04,  1.75816880e-04, -8.63832684e-05,\n",
      "        2.79735046e-04, -1.05973457e-04, -3.45727371e-04,  2.54386337e-04,\n",
      "       -6.32354349e-04,  4.60152020e-04, -4.62616619e-04, -3.05377354e-04,\n",
      "        1.84116390e-04,  6.46377230e-05, -4.34176836e-05,  1.50874141e-04,\n",
      "       -1.85986122e-04, -4.87372221e-04, -2.00818104e-04,  2.02042793e-05,\n",
      "       -1.83736993e-04,  3.08324990e-04,  1.01618934e-06, -6.17221713e-06,\n",
      "       -6.26762980e-04,  1.22276790e-04, -4.33870773e-05,  1.32260553e-04,\n",
      "        3.02320987e-04, -3.10263247e-04,  4.23852354e-04,  1.35857772e-04,\n",
      "       -1.94741762e-04, -2.52239202e-04,  1.30092201e-04,  7.27172010e-05,\n",
      "       -1.13210066e-04,  6.13609503e-04, -3.77494143e-04,  1.73506516e-04,\n",
      "        2.60193756e-05, -4.33476380e-04,  6.96237330e-05,  2.08769605e-04,\n",
      "       -2.72517267e-04, -1.23413236e-04, -6.56707096e-04,  6.74653393e-06,\n",
      "       -5.71930548e-04,  5.40274021e-04, -7.37834125e-05,  4.07000742e-04,\n",
      "        1.28123822e-04, -1.32593630e-06, -9.55690193e-05,  1.91239262e-04,\n",
      "        4.60379641e-04,  6.37504927e-05, -3.75274726e-06, -3.47199166e-05,\n",
      "        6.17884856e-04, -2.82564957e-04, -4.09349683e-04,  2.75969680e-04,\n",
      "       -8.84094261e-05, -4.91711689e-05, -4.21151199e-04, -1.03794948e-04,\n",
      "        2.38941240e-04, -1.49497035e-04,  3.83113220e-04,  1.39549866e-05,\n",
      "       -1.08558466e-04, -2.45881791e-04,  3.34897399e-04,  4.99567715e-04,\n",
      "       -5.54373328e-05,  1.13370559e-04, -7.52660053e-05,  2.23177150e-04],\n",
      "      dtype=float32)), ('soundtrack', array([-2.42948772e-05,  4.27131308e-04,  5.91629883e-04,  5.20400237e-04,\n",
      "       -9.90404951e-05, -4.91452956e-05, -8.53989040e-05, -1.85289115e-04,\n",
      "       -8.25427924e-05, -1.23755817e-04,  3.68062494e-04, -5.39230765e-04,\n",
      "       -5.13935112e-04, -5.89534175e-05, -2.27226352e-04, -3.24139372e-04,\n",
      "        4.44806414e-04,  2.45883362e-04,  8.50350916e-05, -2.60988250e-04,\n",
      "        1.79053590e-04,  2.41960675e-04, -1.27123581e-04,  4.34044458e-04,\n",
      "        1.38322386e-04, -1.68419152e-04, -8.67033668e-05, -3.87892906e-05,\n",
      "       -2.47420976e-04, -1.42678429e-04,  9.24715539e-04, -1.10788795e-04,\n",
      "        4.30473592e-04, -1.42084187e-04,  5.41166577e-04, -8.00249167e-04,\n",
      "       -3.89736029e-04,  2.97279359e-04,  2.01256014e-04,  2.09089936e-04,\n",
      "       -1.43792829e-04,  1.84066375e-04,  4.84442076e-04, -1.99878035e-04,\n",
      "       -6.96168863e-05,  3.99155193e-04, -1.14965675e-04, -1.13392116e-06,\n",
      "        3.64152365e-04,  3.54417978e-04, -2.59668828e-04,  5.39321627e-05,\n",
      "        3.98300530e-04,  1.78806056e-06, -3.39695616e-05,  4.74614964e-04,\n",
      "       -6.11950527e-05, -1.97660993e-04,  1.78616159e-04, -4.40378280e-05,\n",
      "       -3.61509068e-04, -2.62650457e-04, -4.48333703e-05,  9.08120710e-05,\n",
      "        1.18541345e-03, -7.29612657e-05, -2.42301510e-04, -1.63112727e-05,\n",
      "       -9.20770399e-05,  6.63282350e-04, -2.52454018e-04,  1.01474288e-04,\n",
      "        1.47654850e-04,  1.07709697e-04,  2.49499251e-04, -1.42847275e-04,\n",
      "       -4.97611254e-05,  4.86314617e-04, -5.45393385e-04,  2.13527936e-04,\n",
      "        1.13704746e-05,  3.61491402e-04, -1.48241597e-04, -2.07056321e-04,\n",
      "        4.25845385e-04, -5.79870190e-04,  2.67255618e-05, -1.95639994e-04,\n",
      "       -5.09472506e-04,  2.99931125e-04,  3.03242541e-05,  2.06639597e-04,\n",
      "        8.75952537e-05, -4.12880850e-04, -2.13295298e-05, -2.52946047e-04,\n",
      "        1.07092274e-04, -3.48259491e-04, -7.60389303e-05,  5.04017691e-04,\n",
      "        1.35035916e-05, -2.47820426e-05,  5.54421058e-05, -5.49108023e-04,\n",
      "       -1.19769375e-05,  4.73825930e-04, -2.32789331e-04,  1.25041537e-04,\n",
      "       -2.01519055e-04,  1.55934977e-04,  3.81439051e-04,  1.67659542e-04,\n",
      "        1.11181274e-04, -9.12570904e-05, -2.57652835e-04, -4.45329322e-04,\n",
      "        3.30779003e-04, -9.83565551e-05,  3.57465586e-04,  4.87039244e-04,\n",
      "        2.50787270e-04,  3.19803541e-04,  2.83763547e-05, -5.27040451e-04,\n",
      "       -4.94235603e-04,  5.65856404e-04,  2.90585624e-04,  7.30025116e-04,\n",
      "       -2.06443394e-04,  3.75237723e-05,  2.58567627e-04,  1.99112983e-04,\n",
      "        3.58113728e-04,  3.99629265e-04,  4.57493705e-04,  2.79076543e-04,\n",
      "       -2.37801825e-04,  5.28138655e-04,  4.82422620e-04,  3.10286268e-04,\n",
      "       -3.08615330e-04,  1.58987896e-05, -5.69302356e-04, -3.32409400e-04,\n",
      "       -3.70616544e-05,  1.08855966e-04, -1.34085785e-04, -1.18397329e-04,\n",
      "       -1.40460455e-04, -4.83957556e-04, -1.43544414e-04, -4.69123013e-04,\n",
      "       -1.39942524e-04, -1.59559553e-04,  3.13013268e-04,  1.76126443e-04,\n",
      "        4.45940939e-04, -1.32885079e-05, -3.13124387e-04, -4.90636856e-04,\n",
      "        1.16461131e-04, -3.17507714e-04,  2.38176712e-04,  8.19495908e-05,\n",
      "        5.92700497e-04, -1.60735915e-04,  1.85153869e-04, -2.36865351e-04,\n",
      "       -3.30760173e-04, -1.08792540e-03,  1.50742169e-04, -6.68248540e-05,\n",
      "       -2.83354660e-04,  3.68797511e-04,  1.31376553e-04, -4.60762414e-04,\n",
      "        5.62202222e-05, -5.94351848e-04, -6.58058096e-04, -7.89783226e-05,\n",
      "       -5.16154629e-04,  3.90787260e-04,  2.79939850e-04,  4.50454594e-04,\n",
      "       -3.38624872e-04, -2.92478013e-04,  3.13705066e-04, -1.48124222e-04,\n",
      "        1.04724793e-04, -2.44567404e-04,  4.32643137e-05, -6.07267197e-04,\n",
      "        8.54912505e-05,  8.50141223e-05,  2.18662666e-04,  4.13705166e-05,\n",
      "       -6.23639557e-04, -7.07578656e-05, -8.69652358e-05, -4.85751989e-05,\n",
      "       -2.63529982e-05,  4.78650705e-04, -5.91226446e-04,  5.12918981e-04,\n",
      "       -3.37826816e-04,  3.01395950e-04, -2.32455404e-05,  1.36112387e-04,\n",
      "       -3.94518342e-04,  4.55581139e-05, -3.15578538e-04,  1.84660399e-04,\n",
      "       -1.88409205e-04, -2.11761526e-05,  1.15283518e-04,  1.37956260e-04,\n",
      "       -6.12288364e-04, -2.74636637e-04,  2.01514398e-04, -2.68472271e-04,\n",
      "       -4.33624344e-04,  9.66606749e-05,  1.55160800e-04,  8.38958076e-05,\n",
      "        3.28624126e-04, -9.16129866e-05, -8.32536956e-04, -4.48261089e-05,\n",
      "        5.54585131e-06,  1.66768557e-04,  2.00634386e-04, -5.94480334e-05,\n",
      "        3.91644513e-04, -1.62714437e-04,  2.05885008e-04,  2.64683826e-04,\n",
      "        2.48514494e-04,  2.06891898e-04, -4.72903812e-05, -1.27179082e-04,\n",
      "       -2.15011532e-04, -1.98627706e-04,  7.15582224e-04,  2.25617009e-06,\n",
      "        7.45883517e-05, -4.49912390e-04, -4.17996489e-05,  5.15532156e-05,\n",
      "        7.60165218e-04,  7.00792443e-05,  1.65314792e-04,  1.58166396e-04,\n",
      "        6.43276362e-05, -1.74156652e-04, -1.80740040e-04, -3.74411495e-04,\n",
      "       -4.68951257e-05,  7.67728197e-05, -2.34535895e-04, -1.16573926e-03,\n",
      "        3.55010452e-05, -5.23224007e-04,  3.35280856e-05,  2.70821241e-04,\n",
      "       -3.36129946e-04, -1.98860900e-04,  2.67279393e-04, -8.49178032e-05,\n",
      "        4.79303621e-04,  9.66412263e-05, -1.16521631e-04, -6.58625271e-04,\n",
      "        2.36363539e-05, -1.71020627e-04, -4.30313929e-04,  8.73453449e-04,\n",
      "        2.44447321e-04,  1.78962364e-04,  5.27656055e-04, -3.26781097e-04,\n",
      "       -2.11880797e-05,  1.41555822e-04, -3.23631306e-04,  1.49299391e-04,\n",
      "        2.19269336e-04,  5.76265738e-04, -7.47240847e-04, -3.10610689e-04,\n",
      "        5.60020599e-05,  2.85324524e-04, -2.24637959e-04, -4.01811303e-05,\n",
      "        1.78822782e-04, -6.27846457e-04,  3.13054596e-04,  8.21751455e-05,\n",
      "        1.94545610e-05, -2.10262559e-04,  2.62687041e-04, -5.87538489e-05],\n",
      "      dtype=float32)), ('soundtrack', array([-2.42948772e-05,  4.27131308e-04,  5.91629883e-04,  5.20400237e-04,\n",
      "       -9.90404951e-05, -4.91452956e-05, -8.53989040e-05, -1.85289115e-04,\n",
      "       -8.25427924e-05, -1.23755817e-04,  3.68062494e-04, -5.39230765e-04,\n",
      "       -5.13935112e-04, -5.89534175e-05, -2.27226352e-04, -3.24139372e-04,\n",
      "        4.44806414e-04,  2.45883362e-04,  8.50350916e-05, -2.60988250e-04,\n",
      "        1.79053590e-04,  2.41960675e-04, -1.27123581e-04,  4.34044458e-04,\n",
      "        1.38322386e-04, -1.68419152e-04, -8.67033668e-05, -3.87892906e-05,\n",
      "       -2.47420976e-04, -1.42678429e-04,  9.24715539e-04, -1.10788795e-04,\n",
      "        4.30473592e-04, -1.42084187e-04,  5.41166577e-04, -8.00249167e-04,\n",
      "       -3.89736029e-04,  2.97279359e-04,  2.01256014e-04,  2.09089936e-04,\n",
      "       -1.43792829e-04,  1.84066375e-04,  4.84442076e-04, -1.99878035e-04,\n",
      "       -6.96168863e-05,  3.99155193e-04, -1.14965675e-04, -1.13392116e-06,\n",
      "        3.64152365e-04,  3.54417978e-04, -2.59668828e-04,  5.39321627e-05,\n",
      "        3.98300530e-04,  1.78806056e-06, -3.39695616e-05,  4.74614964e-04,\n",
      "       -6.11950527e-05, -1.97660993e-04,  1.78616159e-04, -4.40378280e-05,\n",
      "       -3.61509068e-04, -2.62650457e-04, -4.48333703e-05,  9.08120710e-05,\n",
      "        1.18541345e-03, -7.29612657e-05, -2.42301510e-04, -1.63112727e-05,\n",
      "       -9.20770399e-05,  6.63282350e-04, -2.52454018e-04,  1.01474288e-04,\n",
      "        1.47654850e-04,  1.07709697e-04,  2.49499251e-04, -1.42847275e-04,\n",
      "       -4.97611254e-05,  4.86314617e-04, -5.45393385e-04,  2.13527936e-04,\n",
      "        1.13704746e-05,  3.61491402e-04, -1.48241597e-04, -2.07056321e-04,\n",
      "        4.25845385e-04, -5.79870190e-04,  2.67255618e-05, -1.95639994e-04,\n",
      "       -5.09472506e-04,  2.99931125e-04,  3.03242541e-05,  2.06639597e-04,\n",
      "        8.75952537e-05, -4.12880850e-04, -2.13295298e-05, -2.52946047e-04,\n",
      "        1.07092274e-04, -3.48259491e-04, -7.60389303e-05,  5.04017691e-04,\n",
      "        1.35035916e-05, -2.47820426e-05,  5.54421058e-05, -5.49108023e-04,\n",
      "       -1.19769375e-05,  4.73825930e-04, -2.32789331e-04,  1.25041537e-04,\n",
      "       -2.01519055e-04,  1.55934977e-04,  3.81439051e-04,  1.67659542e-04,\n",
      "        1.11181274e-04, -9.12570904e-05, -2.57652835e-04, -4.45329322e-04,\n",
      "        3.30779003e-04, -9.83565551e-05,  3.57465586e-04,  4.87039244e-04,\n",
      "        2.50787270e-04,  3.19803541e-04,  2.83763547e-05, -5.27040451e-04,\n",
      "       -4.94235603e-04,  5.65856404e-04,  2.90585624e-04,  7.30025116e-04,\n",
      "       -2.06443394e-04,  3.75237723e-05,  2.58567627e-04,  1.99112983e-04,\n",
      "        3.58113728e-04,  3.99629265e-04,  4.57493705e-04,  2.79076543e-04,\n",
      "       -2.37801825e-04,  5.28138655e-04,  4.82422620e-04,  3.10286268e-04,\n",
      "       -3.08615330e-04,  1.58987896e-05, -5.69302356e-04, -3.32409400e-04,\n",
      "       -3.70616544e-05,  1.08855966e-04, -1.34085785e-04, -1.18397329e-04,\n",
      "       -1.40460455e-04, -4.83957556e-04, -1.43544414e-04, -4.69123013e-04,\n",
      "       -1.39942524e-04, -1.59559553e-04,  3.13013268e-04,  1.76126443e-04,\n",
      "        4.45940939e-04, -1.32885079e-05, -3.13124387e-04, -4.90636856e-04,\n",
      "        1.16461131e-04, -3.17507714e-04,  2.38176712e-04,  8.19495908e-05,\n",
      "        5.92700497e-04, -1.60735915e-04,  1.85153869e-04, -2.36865351e-04,\n",
      "       -3.30760173e-04, -1.08792540e-03,  1.50742169e-04, -6.68248540e-05,\n",
      "       -2.83354660e-04,  3.68797511e-04,  1.31376553e-04, -4.60762414e-04,\n",
      "        5.62202222e-05, -5.94351848e-04, -6.58058096e-04, -7.89783226e-05,\n",
      "       -5.16154629e-04,  3.90787260e-04,  2.79939850e-04,  4.50454594e-04,\n",
      "       -3.38624872e-04, -2.92478013e-04,  3.13705066e-04, -1.48124222e-04,\n",
      "        1.04724793e-04, -2.44567404e-04,  4.32643137e-05, -6.07267197e-04,\n",
      "        8.54912505e-05,  8.50141223e-05,  2.18662666e-04,  4.13705166e-05,\n",
      "       -6.23639557e-04, -7.07578656e-05, -8.69652358e-05, -4.85751989e-05,\n",
      "       -2.63529982e-05,  4.78650705e-04, -5.91226446e-04,  5.12918981e-04,\n",
      "       -3.37826816e-04,  3.01395950e-04, -2.32455404e-05,  1.36112387e-04,\n",
      "       -3.94518342e-04,  4.55581139e-05, -3.15578538e-04,  1.84660399e-04,\n",
      "       -1.88409205e-04, -2.11761526e-05,  1.15283518e-04,  1.37956260e-04,\n",
      "       -6.12288364e-04, -2.74636637e-04,  2.01514398e-04, -2.68472271e-04,\n",
      "       -4.33624344e-04,  9.66606749e-05,  1.55160800e-04,  8.38958076e-05,\n",
      "        3.28624126e-04, -9.16129866e-05, -8.32536956e-04, -4.48261089e-05,\n",
      "        5.54585131e-06,  1.66768557e-04,  2.00634386e-04, -5.94480334e-05,\n",
      "        3.91644513e-04, -1.62714437e-04,  2.05885008e-04,  2.64683826e-04,\n",
      "        2.48514494e-04,  2.06891898e-04, -4.72903812e-05, -1.27179082e-04,\n",
      "       -2.15011532e-04, -1.98627706e-04,  7.15582224e-04,  2.25617009e-06,\n",
      "        7.45883517e-05, -4.49912390e-04, -4.17996489e-05,  5.15532156e-05,\n",
      "        7.60165218e-04,  7.00792443e-05,  1.65314792e-04,  1.58166396e-04,\n",
      "        6.43276362e-05, -1.74156652e-04, -1.80740040e-04, -3.74411495e-04,\n",
      "       -4.68951257e-05,  7.67728197e-05, -2.34535895e-04, -1.16573926e-03,\n",
      "        3.55010452e-05, -5.23224007e-04,  3.35280856e-05,  2.70821241e-04,\n",
      "       -3.36129946e-04, -1.98860900e-04,  2.67279393e-04, -8.49178032e-05,\n",
      "        4.79303621e-04,  9.66412263e-05, -1.16521631e-04, -6.58625271e-04,\n",
      "        2.36363539e-05, -1.71020627e-04, -4.30313929e-04,  8.73453449e-04,\n",
      "        2.44447321e-04,  1.78962364e-04,  5.27656055e-04, -3.26781097e-04,\n",
      "       -2.11880797e-05,  1.41555822e-04, -3.23631306e-04,  1.49299391e-04,\n",
      "        2.19269336e-04,  5.76265738e-04, -7.47240847e-04, -3.10610689e-04,\n",
      "        5.60020599e-05,  2.85324524e-04, -2.24637959e-04, -4.01811303e-05,\n",
      "        1.78822782e-04, -6.27846457e-04,  3.13054596e-04,  8.21751455e-05,\n",
      "        1.94545610e-05, -2.10262559e-04,  2.62687041e-04, -5.87538489e-05],\n",
      "      dtype=float32)), ('distracting', array([-3.13952187e-04,  2.73470650e-04, -6.51673181e-04,  2.15634893e-04,\n",
      "       -4.40285192e-04, -1.08406755e-04, -2.27903045e-04, -9.33842384e-05,\n",
      "       -2.96143116e-04, -1.10754227e-04,  5.65157156e-04,  2.19287642e-04,\n",
      "       -2.04830445e-04,  4.66807796e-05,  6.20418905e-06,  1.31468216e-04,\n",
      "        5.22792339e-04, -3.69011133e-04, -1.68785715e-04, -1.76615664e-04,\n",
      "       -4.49274114e-04,  3.55117489e-04, -5.62188390e-04, -8.29550263e-04,\n",
      "       -9.55394717e-05, -2.84063077e-04,  1.55845235e-04,  6.00051368e-04,\n",
      "       -1.18994481e-04, -3.43633234e-04,  1.75861875e-04, -1.25289356e-04,\n",
      "       -7.28027488e-04,  3.39112630e-05,  2.16942601e-04, -5.58810018e-04,\n",
      "       -1.22250731e-05,  6.28662528e-05, -4.69932420e-04,  5.80028165e-04,\n",
      "        2.78125401e-04,  3.45212553e-04, -3.53441195e-04,  1.12533620e-04,\n",
      "       -2.11297491e-04,  4.17841249e-04,  4.22308040e-05, -4.29335603e-04,\n",
      "        2.63934111e-04,  1.46113525e-04, -7.41697950e-05, -3.82705184e-04,\n",
      "       -5.89351403e-04, -5.60017012e-04,  3.10860050e-04, -8.24469316e-04,\n",
      "        3.45545908e-04, -8.23071750e-05, -1.70095765e-04,  3.16138292e-04,\n",
      "       -3.31928051e-04,  3.31407464e-05, -5.27504832e-04,  3.51800089e-04,\n",
      "        3.83584236e-04,  6.28362468e-05, -1.34774718e-05,  1.73509761e-04,\n",
      "        7.37374503e-05,  5.16741711e-04, -4.01220837e-04, -7.79222173e-05,\n",
      "        7.36023940e-05, -3.22651409e-04,  5.65254122e-05, -6.96909774e-05,\n",
      "        2.56747386e-04,  1.76955218e-04, -7.06931532e-05,  1.02642080e-04,\n",
      "        1.14173803e-04,  8.87020069e-05, -4.28358879e-04, -1.86563819e-04,\n",
      "        1.95334622e-04,  1.01325946e-04, -1.19020267e-04, -8.44620081e-05,\n",
      "       -9.50987684e-04,  2.87136441e-04, -4.36949776e-05,  2.85650283e-04,\n",
      "       -3.42869695e-04, -6.17387341e-05,  5.42659778e-04,  1.76154455e-04,\n",
      "       -6.62329141e-04, -2.81206332e-04,  4.17664443e-04, -6.37326331e-04,\n",
      "        6.05369161e-04, -3.27545458e-05, -3.65920103e-04, -3.14914592e-04,\n",
      "        5.32876176e-04,  3.24271386e-04,  9.40928949e-05, -8.95923877e-05,\n",
      "        3.30564566e-04, -1.31009336e-04, -5.55381412e-04,  6.50452741e-04,\n",
      "       -3.39443330e-04, -3.37058824e-04,  1.10253408e-04,  1.21906254e-04,\n",
      "       -3.74509662e-04,  1.09201530e-04, -6.66878113e-05,  1.43945736e-05,\n",
      "       -1.16515781e-04,  6.01118256e-04,  1.75680922e-04, -1.36681656e-05,\n",
      "        1.72783737e-04, -5.52053913e-04, -2.25406711e-06,  1.07673499e-04,\n",
      "        3.53262731e-05, -5.40329434e-04, -2.69835495e-04, -4.42401157e-04,\n",
      "       -2.28264718e-04, -2.28049117e-04,  4.75444278e-04, -7.40681935e-05,\n",
      "        3.87947483e-04, -6.17366532e-05,  3.13953729e-04,  1.53139888e-04,\n",
      "        2.35360087e-04,  1.88387319e-04,  1.14344048e-05, -3.43064166e-04,\n",
      "       -4.31246117e-05,  2.26985489e-04,  3.40469327e-04, -3.12430697e-04,\n",
      "       -4.46516322e-04,  2.18178713e-04, -3.93758528e-04, -9.48817033e-05,\n",
      "        4.06259642e-04, -1.86477744e-04,  4.26120969e-05,  3.50225673e-05,\n",
      "        4.43576195e-04, -6.58808101e-04, -6.83226899e-05, -2.73462556e-05,\n",
      "        4.49809682e-04,  2.56176252e-04,  1.33804831e-04, -1.45246275e-04,\n",
      "        5.24380826e-04, -7.09274085e-04, -3.58538702e-04,  5.54202066e-04,\n",
      "       -3.85898456e-04,  3.97897034e-04, -1.82808522e-04, -6.36190351e-04,\n",
      "       -1.96221998e-04, -1.58873343e-04, -3.27105081e-05,  1.02298407e-04,\n",
      "       -1.33121677e-04,  6.86253916e-05, -1.11515168e-04, -3.16171470e-04,\n",
      "       -5.58569387e-04,  4.47543833e-04, -4.68021346e-04,  7.90290884e-04,\n",
      "        1.21088480e-04,  3.36676180e-06,  2.16088796e-04, -2.46528478e-04,\n",
      "        1.53196728e-04,  4.60279669e-04,  4.59205941e-04, -1.09384207e-04,\n",
      "       -5.30324724e-05, -2.63862108e-04, -2.80780980e-04,  2.19313821e-04,\n",
      "       -2.81393412e-04,  1.35227805e-04, -2.47577438e-04,  2.53685866e-04,\n",
      "       -3.44878994e-04, -5.56713276e-05,  3.14015633e-04, -2.09088685e-04,\n",
      "        3.94528106e-05, -1.12777379e-04,  4.03520753e-05, -8.83099638e-05,\n",
      "        3.95147508e-04,  4.60544019e-04,  2.39865167e-05, -1.50363285e-05,\n",
      "        2.93221674e-04,  1.96002889e-04, -5.22324932e-04,  1.91535059e-04,\n",
      "       -3.54722695e-04,  3.93197668e-04,  5.24400275e-05, -1.57238683e-05,\n",
      "       -1.39364754e-04,  2.97727311e-05, -3.20244581e-04, -4.41179553e-04,\n",
      "       -1.35405964e-04,  1.29014399e-04, -1.25191800e-04,  4.08070511e-04,\n",
      "        1.25120976e-04,  2.38621025e-04, -7.49976534e-05,  2.98414641e-04,\n",
      "       -8.66262344e-05, -5.81318163e-04,  3.61750892e-04,  2.23030613e-04,\n",
      "        4.93452768e-04,  5.02939976e-04, -2.80684235e-05, -3.14333767e-04,\n",
      "        4.15837974e-04, -2.01101531e-04,  2.50576559e-04, -2.29549318e-04,\n",
      "       -7.87128665e-05, -1.09535948e-04,  5.37856366e-04,  1.84749399e-04,\n",
      "       -3.38696525e-04, -3.60432241e-05, -6.13241573e-04,  3.88434390e-04,\n",
      "        3.48034315e-04, -3.64742082e-05,  1.30867702e-04,  3.82901257e-04,\n",
      "        3.12493474e-04,  2.15673776e-04,  3.66123495e-05, -2.69285083e-04,\n",
      "        4.86691570e-04,  4.49189683e-05,  4.79826005e-04,  3.01793712e-04,\n",
      "       -7.14404305e-05,  3.12779128e-04,  3.92241578e-04,  6.10207382e-04,\n",
      "       -5.28455770e-04, -4.22228710e-04, -2.57623149e-04, -8.49857315e-05,\n",
      "       -2.61820416e-04,  3.52716917e-04,  8.32548467e-05, -4.29835083e-04,\n",
      "        5.85068483e-06, -3.04161531e-05,  7.11275716e-05,  3.34628785e-05,\n",
      "        4.43450670e-04, -2.31780301e-04, -1.31677341e-04,  3.82064645e-05,\n",
      "        3.81701648e-06, -2.68855674e-05, -3.38232989e-04,  1.13768419e-05,\n",
      "       -1.85410536e-04,  2.25500276e-04,  5.58354310e-04,  3.04237561e-04,\n",
      "       -1.24460203e-04,  3.74164345e-04,  2.02448922e-04, -1.06509606e-05,\n",
      "       -5.87128685e-04,  2.16598375e-04,  6.45221226e-05,  3.25487345e-04],\n",
      "      dtype=float32)), ('collection', array([ 8.16953660e-04,  4.10841778e-04,  5.29015262e-04, -2.41976115e-04,\n",
      "        3.90853063e-04,  2.84218928e-04, -5.01771749e-04, -1.04534593e-04,\n",
      "        4.23331250e-04,  8.59895546e-04,  4.66504745e-04, -1.31733410e-04,\n",
      "       -4.79750888e-04,  1.11346068e-04, -2.99411156e-04,  2.92073149e-04,\n",
      "       -1.65521433e-05,  2.08910991e-04,  4.52749693e-04, -1.74319532e-04,\n",
      "       -2.66228046e-04, -2.25396740e-04, -2.60173583e-05,  5.37862361e-05,\n",
      "       -3.52340925e-04,  8.69807191e-05,  5.35297790e-04, -3.77157732e-04,\n",
      "       -1.52663022e-04, -1.90592600e-05, -5.99478662e-04, -7.24872225e-04,\n",
      "       -1.35076887e-04,  1.45593061e-04, -2.32468796e-04,  3.00031912e-04,\n",
      "        2.17872366e-04, -4.08555992e-04,  1.20301811e-04,  1.15480383e-04,\n",
      "        6.12707285e-04,  8.49372082e-05,  6.47398585e-04,  1.91488871e-04,\n",
      "        2.89608899e-04,  5.93879435e-04, -3.48858710e-04,  2.60634988e-04,\n",
      "        3.93066643e-04,  2.94765923e-04, -1.26165207e-04, -5.50833996e-04,\n",
      "        5.62686066e-04, -1.57673843e-04, -8.55617182e-05,  3.87758599e-04,\n",
      "       -1.49519808e-04, -4.03446378e-04,  3.36057798e-04, -2.19688227e-04,\n",
      "        3.38651676e-04, -4.54378052e-04,  8.95557387e-05, -3.16635327e-04,\n",
      "        1.84946348e-05,  3.54326010e-04, -2.76452221e-04, -4.30937158e-04,\n",
      "        3.12159187e-04,  2.32070568e-04,  3.89954686e-04, -1.09869201e-04,\n",
      "        3.51804454e-04,  8.40289067e-05, -1.27323132e-04,  5.95904712e-04,\n",
      "       -2.43920120e-04,  7.63313346e-06, -2.16797762e-05,  2.16800312e-04,\n",
      "       -2.51473510e-04,  2.64136994e-04,  5.07441509e-05, -6.04364264e-04,\n",
      "        4.04830353e-04, -2.35098531e-04,  3.52641306e-04,  4.09498374e-04,\n",
      "       -1.94394903e-04,  1.77769063e-04,  5.67175914e-04, -1.89712227e-04,\n",
      "        1.30916203e-04,  5.23463241e-04, -6.19269599e-07,  4.78395814e-04,\n",
      "       -2.78440071e-04,  9.14756019e-05, -1.60932628e-04,  2.29637575e-04,\n",
      "       -4.36896407e-05, -1.29771768e-04,  2.76489096e-04,  4.41648765e-04,\n",
      "        3.04772431e-04, -4.66561323e-04, -3.14889010e-04,  9.59685785e-05,\n",
      "        4.92985302e-04, -3.16450431e-04, -2.08993137e-04,  3.81235266e-04,\n",
      "       -6.05164423e-05, -1.38584082e-05, -8.86002381e-05,  4.24300582e-04,\n",
      "        1.42770106e-04,  2.35028449e-04,  1.32586365e-05,  1.22055371e-05,\n",
      "       -3.76504613e-05, -7.37597176e-04, -1.52651657e-04, -5.97211283e-06,\n",
      "        2.17238281e-04, -2.04559678e-04,  2.47953663e-04, -3.96473886e-04,\n",
      "       -2.63543683e-04,  2.52592843e-04, -4.76927496e-04, -3.52920790e-04,\n",
      "        5.22878952e-04, -1.97547328e-04,  3.78136057e-04,  1.49697109e-04,\n",
      "        1.10775698e-04,  1.39523938e-04, -4.77317226e-04,  1.31291108e-05,\n",
      "       -2.41674396e-04,  6.43925741e-05,  1.70366955e-04, -1.58381459e-04,\n",
      "        2.28095796e-05, -6.50955099e-06, -1.46167931e-05, -3.04206944e-04,\n",
      "       -2.57645268e-04,  2.17218752e-04, -4.92875406e-04, -1.64033961e-04,\n",
      "       -8.15804407e-04, -1.74927089e-04, -3.64191837e-05,  1.47202727e-05,\n",
      "        8.67750423e-05,  1.88336508e-05, -6.30146184e-04, -2.46165437e-04,\n",
      "        1.86887381e-04, -2.18929243e-04,  6.94787086e-05, -7.04232589e-05,\n",
      "       -1.04977305e-04, -4.58285707e-04,  9.45545908e-05, -3.54607590e-04,\n",
      "       -1.41219120e-04, -4.68216720e-04, -2.08848156e-04, -1.92044055e-04,\n",
      "        8.20352871e-05, -2.17730703e-04,  4.35170572e-04, -2.91391363e-04,\n",
      "        1.67011051e-04, -3.45121254e-04, -9.94276270e-05, -2.02201772e-04,\n",
      "        1.57490995e-05,  2.09880182e-05, -6.08341688e-05,  3.61365092e-05,\n",
      "       -1.53181230e-04,  4.17076481e-05, -8.24753952e-05, -3.85342835e-04,\n",
      "       -4.71441635e-05,  1.70850908e-04,  3.61457205e-04, -5.28149307e-04,\n",
      "        1.02930833e-04, -3.93728551e-05,  3.42629093e-04, -2.67837109e-04,\n",
      "        2.29119818e-04,  1.02377075e-04, -5.53710212e-04,  3.90242167e-05,\n",
      "       -5.29127545e-04, -2.89129064e-04,  1.13751601e-04, -5.19000925e-04,\n",
      "        3.32233030e-04,  4.75828274e-04,  2.96450395e-04, -2.69545359e-04,\n",
      "        1.51435437e-04, -4.62765252e-04,  3.01050808e-04, -2.85487040e-04,\n",
      "        5.81606815e-04, -7.14160051e-05, -1.14688628e-05, -3.81034857e-04,\n",
      "        3.60701932e-04,  3.86118045e-05,  2.54970104e-07,  1.32836387e-04,\n",
      "        4.88778285e-04,  7.24618440e-05, -4.88096615e-04,  3.59612401e-04,\n",
      "        1.37609779e-04,  3.36379453e-05, -3.06638918e-04, -1.30166780e-04,\n",
      "        1.64388748e-05,  1.72119151e-04, -4.10566031e-07, -2.58558226e-04,\n",
      "       -1.14245428e-04,  3.03775687e-05, -6.42648301e-05, -1.83286393e-04,\n",
      "        4.41631419e-04, -1.79419498e-04, -5.97551290e-04, -3.00034590e-04,\n",
      "       -1.71740510e-04,  6.84826518e-05, -4.46510181e-04,  3.71689268e-04,\n",
      "       -1.16463023e-04,  4.12906928e-04, -3.27941001e-04, -2.08766491e-04,\n",
      "       -8.71489465e-05, -2.18772184e-04,  1.90390536e-04,  5.13611803e-06,\n",
      "        1.22231359e-04, -1.43753714e-04,  1.34136513e-04,  2.91592642e-05,\n",
      "        3.37102218e-04, -9.24258275e-05, -3.07797891e-04,  2.45477189e-04,\n",
      "       -1.76215428e-04, -1.45616330e-04,  6.88539103e-06, -8.82318243e-04,\n",
      "        3.73414747e-04, -5.84342517e-04, -6.94362388e-04, -8.63094028e-05,\n",
      "        5.21956594e-04,  1.10671237e-04, -2.71000008e-05,  2.23742798e-04,\n",
      "        4.04420687e-04,  1.16873343e-04,  2.36945751e-04, -2.05243719e-04,\n",
      "        2.26412318e-04, -2.71356810e-04,  3.32522213e-05,  9.77208838e-05,\n",
      "       -1.40289194e-04, -2.60846660e-04, -1.79805793e-04, -1.21891033e-04,\n",
      "       -3.20244173e-04, -3.43135995e-04, -5.42731956e-04,  9.32688999e-05,\n",
      "       -2.98756408e-04, -1.03303217e-04, -5.64653077e-04, -2.23497427e-05,\n",
      "       -5.92053002e-05, -2.77075102e-04,  7.03004189e-05, -2.53385195e-04,\n",
      "        1.98284280e-04,  1.14032904e-04, -3.15162528e-04, -2.74815218e-04],\n",
      "      dtype=float32))]\n",
      "Total time:  2.3815765380859375\n",
      "====================================\n",
      "METHOD:  elmo\n",
      "Character_id:  tensor([[[259,  71, 106, 115, 116, 117, 260, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261],\n",
      "         [259, 116, 102, 111, 117, 102, 111, 100, 102, 260, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261],\n",
      "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261]],\n",
      "\n",
      "        [[259,  66, 111, 112, 117, 105, 102, 115, 260, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261],\n",
      "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "          261, 261, 261, 261, 261, 261, 261, 261],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0,   0,   0,   0,   0,   0,   0,   0]]]) \n",
      "Embedding:  {'elmo_representations': [tensor([[[ 0.1474, -0.1475,  0.1376,  ...,  0.0270, -0.4051, -0.0498],\n",
      "         [ 0.2394,  0.0769,  0.4126,  ..., -0.1671, -0.1707,  0.3884],\n",
      "         [-0.7602, -0.4944, -0.5355,  ..., -0.0803,  0.0361,  0.1128]],\n",
      "\n",
      "        [[ 0.2603, -0.4437,  0.2726,  ..., -0.0830, -0.1522, -0.1361],\n",
      "         [-0.7772, -0.4294, -0.2651,  ..., -0.0803,  0.0361,  0.1128],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<CopySlices>)], 'mask': tensor([[ True,  True,  True],\n",
      "        [ True,  True, False]])}\n",
      "Total time:  2.6266441345214844\n",
      "====================================\n",
      "METHOD:  gpt2\n",
      "[('Despite', [8332]), ('the', [1169]), ('fact', [22584]), ('that', [5562]), ('I', [40]), ('have', [14150]), ('only', [8807]), ('played', [21542]), ('a', [64]), ('small', [17470]), ('portion', [16864]), ('of', [1659]), ('the', [1169]), ('game', [6057]), ('the', [1169]), ('music', [28965]), ('I', [40]), ('heard', [23636]), ('plus', [9541]), ('the', [1169]), ('connection', [38659]), ('to', [1462]), ('Chrono', [1925, 1313, 78]), ('Trigger', [48344]), ('which', [4758]), ('wa', [10247]), ('great', [18223]), ('a', [64]), ('well', [4053]), ('led', [992]), ('me', [1326]), ('to', [1462]), ('purchase', [79, 18737]), ('the', [1169]), ('soundtrack', [23661, 11659]), ('and', [392]), ('it', [270]), ('remains', [2787, 1299]), ('one', [505]), ('of', [1659]), ('my', [1820]), ('favorite', [35200]), ('album', [40916]), ('There', [1858]), ('is', [271]), ('an', [272]), ('incredible', [1939, 26260]), ('mix', [19816]), ('of', [1659]), ('fun', [12543]), ('epic', [538, 291]), ('and', [392]), ('emotional', [368, 25453]), ('song', [34050]), ('Those', [9627]), ('sad', [82, 324]), ('and', [392]), ('beautiful', [40544, 4135]), ('track', [11659]), ('I', [40]), ('especially', [16480]), ('like', [2339]), ('a', [64]), ('there', [8117]), ('not', [1662]), ('too', [18820]), ('many', [21834]), ('of', [1659]), ('those', [25591]), ('kind', [11031]), ('of', [1659]), ('song', [34050]), ('in', [259]), ('my', [1820]), ('other', [847]), ('video', [15588]), ('game', [6057]), ('soundtrack', [23661, 11659]), ('I', [40]), ('must', [27238]), ('admit', [324, 2781]), ('that', [5562]), ('one', [505]), ('of', [1659]), ('the', [1169]), ('song', [34050]), ('LifeA', [14662, 32]), ('Distant', [35, 10167]), ('Promise', [24129, 786]), ('ha', [3099]), ('brought', [65, 2909]), ('tear', [83, 451]), ('to', [1462]), ('my', [1820]), ('eye', [25379]), ('on', [261]), ('many', [21834]), ('occasion', [13966, 4247]), ('My', [3666]), ('one', [505]), ('complaint', [23855, 2913]), ('about', [10755]), ('this', [5661]), ('soundtrack', [23661, 11659]), ('is', [271]), ('that', [5562]), ('they', [9930]), ('use', [1904]), ('guitar', [70, 5013, 283]), ('fretting', [69, 1186, 889]), ('effect', [10760]), ('in', [259]), ('many', [21834]), ('of', [1659]), ('the', [1169]), ('song', [34050]), ('which', [4758]), ('I', [40]), ('find', [19796]), ('distracting', [17080, 974, 278]), ('But', [1537]), ('even', [10197]), ('if', [361]), ('those', [25591]), ('werent', [86, 9100]), ('included', [259, 10341]), ('I', [40]), ('would', [19188]), ('still', [24219]), ('consider', [44353]), ('the', [1169]), ('collection', [43681]), ('worth', [9268]), ('it', [270])]\n",
      "Total time:  6.025370836257935\n",
      "====================================\n",
      "METHOD:  bert\n",
      "torch.Size([1, 3]) [['Despite', 'the', 'fact', 'that', 'I', 'have', 'only', 'played', 'a', 'small', 'portion', 'of', 'the', 'game', 'the', 'music', 'I', 'heard', 'plus', 'the', 'connection', 'to', 'Chrono', 'Trigger', 'which', 'wa', 'great', 'a', 'well', 'led', 'me', 'to', 'purchase', 'the', 'soundtrack', 'and', 'it', 'remains', 'one', 'of', 'my', 'favorite', 'album', 'There', 'is', 'an', 'incredible', 'mix', 'of', 'fun', 'epic', 'and', 'emotional', 'song', 'Those', 'sad', 'and', 'beautiful', 'track', 'I', 'especially', 'like', 'a', 'there', 'not', 'too', 'many', 'of', 'those', 'kind', 'of', 'song', 'in', 'my', 'other', 'video', 'game', 'soundtrack', 'I', 'must', 'admit', 'that', 'one', 'of', 'the', 'song', 'LifeA', 'Distant', 'Promise', 'ha', 'brought', 'tear', 'to', 'my', 'eye', 'on', 'many', 'occasion', 'My', 'one', 'complaint', 'about', 'this', 'soundtrack', 'is', 'that', 'they', 'use', 'guitar', 'fretting', 'effect', 'in', 'many', 'of', 'the', 'song', 'which', 'I', 'find', 'distracting', 'But', 'even', 'if', 'those', 'werent', 'included', 'I', 'would', 'still', 'consider', 'the', 'collection', 'worth', 'it']] 1\n",
      "Total time:  5.1634461879730225\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "methods = [\"bert\",\"gpt2\",\"elmo\",\"fastext\", \"glove\", \"word2vec\", \"tfidf\", \"ngrams\", \"BOW\"]\n",
    "for m in methods[::-1]:\n",
    "    print(\"METHOD: \", m)\n",
    "    start = time.time()\n",
    "    vectorisation(df[\"review\"].iloc[:1].tolist(), method=m)\n",
    "    end = time.time()\n",
    "    print(\"Total time: \", end-start)\n",
    "    print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "85cd5683-1b45-4567-b3d1-2bc989682552",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "\n",
    "from torchtext.legacy import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "\n",
    "import torch\n",
    "from allennlp.data import Token, Vocabulary, TokenIndexer, Tokenizer\n",
    "from allennlp.modules.token_embedders import (\n",
    "    Embedding,\n",
    "    TokenCharactersEncoder,\n",
    "    ElmoTokenEmbedder,\n",
    "    PretrainedTransformerEmbedder,\n",
    "    PretrainedTransformerMismatchedEmbedder,\n",
    ")\n",
    "from allennlp.data.token_indexers import (\n",
    "    SingleIdTokenIndexer,\n",
    "    TokenCharactersIndexer,\n",
    "    ELMoTokenCharactersIndexer,\n",
    "    PretrainedTransformerIndexer,\n",
    "    PretrainedTransformerMismatchedIndexer,\n",
    ")\n",
    "from allennlp.data.fields import ListField, TextField\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "\n",
    "import nltk\n",
    "\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pyprind\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8396d-28a8-49ac-9e4b-f9fbcebdf010",
   "metadata": {},
   "source": [
    "Issue:\n",
    "\n",
    "* https://github.com/pytorch/text/issues/1342\n",
    "==> solution: \n",
    "torch                         1.10.0\n",
    "torchtext                     0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c14de9-16a5-462f-96d1-17f5265a7fb6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e86a2f6b-5218-4af2-82f9-41d92ab4f0b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True cuda\n"
     ]
    }
   ],
   "source": [
    "spacy = spacy.load(\"en_core_web_sm\")\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "print(is_cuda, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7dc7a649-e17d-46b7-a412-893ae76d8aaa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ALLEN NLP ELMO model\n",
    "# References:\n",
    "# 1. https://github.com/allenai/allennlp/issues/1737\n",
    "# 2. https://allenai.github.io/allennlp-website/interpret\n",
    "# 3. https://guide.allennlp.org/\n",
    "class elmo:\n",
    "    def __init__(self, tokens=[tk for tk in df[\"review\"].iloc[10].split()], transformer_model=\"google/reformer-crime-and-punishment\"):\n",
    "        # This pattern is typically used in cases where your input data is already\n",
    "        # tokenized, so we're showing that here.\n",
    "        self.text_tokens = tokens#[tk for tk in df[\"review\"].iloc[10].split()]#[\"This\", \"is\", \"some\", \"frandibulous\", \"text\", \".\"]\n",
    "        self.tokens = [Token(x) for x in self.text_tokens]\n",
    "        #print(self.tokens)\n",
    "\n",
    "        # We're using a very small transformer here so that it runs quickly in binder. You\n",
    "        # can change this to any transformer model name supported by Hugging Face.\n",
    "        self.transformer_model = transformer_model\n",
    "        \n",
    "        # Represents the list of word tokens with a sequences of wordpieces as determined\n",
    "        # by the transformer's tokenizer.  This actually results in a pretty complex data\n",
    "        # type, which you can see by running this.  It's complicated because we need to\n",
    "        # know how to combine the wordpieces back into words after running the\n",
    "        # transformer.\n",
    "        self.indexer = PretrainedTransformerMismatchedIndexer(model_name=self.transformer_model)\n",
    "\n",
    "        self.text_field = TextField(self.tokens, {\"transformer\": self.indexer})\n",
    "        self.text_field.index(Vocabulary())\n",
    "        self.token_tensor = self.text_field.as_tensor(self.text_field.get_padding_lengths())\n",
    "\n",
    "        # There are two key things to notice in this output.  First, there are two masks:\n",
    "        # `mask` is a word-level mask that gets used in the utility functions described in\n",
    "        # the last section of this chapter.  `wordpiece_mask` gets used by the `Embedder`\n",
    "        # itself.  Second, there is an `offsets` tensor that gives start and end wordpiece\n",
    "        # indices for the original tokens.  In the embedder, we grab these, average all of\n",
    "        # the wordpieces for each token, and return the result.\n",
    "        print(\"Indexed tensors:\", self.token_tensor)\n",
    "\n",
    "    def embedding(self):\n",
    "        embedding = PretrainedTransformerMismatchedEmbedder(model_name=self.transformer_model)\n",
    "\n",
    "        embedder = BasicTextFieldEmbedder(token_embedders={\"transformer\": embedding})\n",
    "\n",
    "        tensor_dict = self.text_field.batch_tensors([self.token_tensor])\n",
    "        embedded_tokens = embedder(tensor_dict)\n",
    "        print(\"Embedded tokens size:\", embedded_tokens.size())\n",
    "        #print(\"Embedded tokens:\", embedded_tokens)\n",
    "        return embedder, embedded_tokens\n",
    "        \n",
    "# FastText implementation\n",
    "class fast_texTrain:\n",
    "    def __init__(self, train_text = df['review'].tolist(), train_label = df['polarity'].tolist()):\n",
    "        self.all_text = train_text\n",
    "        self.all_label = train_label\n",
    "        self.fast_datapoints = []\n",
    "        #Need to convert data into this format: __label__<label value><space><associated datapoint>\n",
    "        for i in range(len(self.all_text)):\n",
    "            sample = \"__label__\" + str(self.all_label[i]) + \" \" + self.all_text[i]\n",
    "            self.fast_datapoints.append(sample)\n",
    "        self.filename = \"train_fastext\" + time.strftime(\"%Y-%b-%a %H-%M-%S\", time.gmtime()) + \".txt\"\n",
    "        with open(self.filename, \"w\") as file:\n",
    "            for data in self.fast_datapoints:\n",
    "                file.write(data)\n",
    "                file.write(\"\\n\")\n",
    "            file.close()\n",
    "    def train(self):\n",
    "        model = fasttext.train_supervised(self.filename)\n",
    "        return model\n",
    "            \n",
    "# Reference: https://www.kaggle.com/code/kuldeep7688/simple-rnn-using-glove-embeddings-in-pytorch\n",
    "# Simple RNN model using GLOVe embedding for sentiment classification\n",
    "class glove_embed:\n",
    "    def __init__(self):\n",
    "        self.TEXT = data.Field(sequential=True, tokenize=\"spacy\")\n",
    "        self.LABEL = data.LabelField(sequential=False, dtype=torch.long)\n",
    "        self.train_data, self.test_data = data.TabularDataset.splits(path=\"./data/\", train=\"amazon_small.csv\",\n",
    "                                                test=\"test_amazon_small.csv\", format=\"csv\",\n",
    "                                                skip_header=True,\n",
    "                                                fields=[('Text', self.TEXT),('Label', self.LABEL)])\n",
    "        self.TEXT.build_vocab(self.train_data, \n",
    "                              vectors=torchtext.vocab.Vectors(\"./embeddings/glove.6B.300d.txt\"),\n",
    "                             max_size=20000, min_freq=10)\n",
    "        self.LABEL.build_vocab(self.train_data)\n",
    "        print(f\"Length of TRAIN_data: {len(self.train_data)},Length of TEST_data: {len( self.test_data)}\",\n",
    "             f\"\\nUnique tokens in :\\nTEXT vocab:{len(self.TEXT.vocab)},\\nLABEL vocab:{len(self.LABEL.vocab)}\")\n",
    "\n",
    "        self.Batch_size = 10\n",
    "        self.device = device\n",
    "        self.train_iterator, self.test_iterator = data.BucketIterator.splits((self.train_data, self.test_data),\n",
    "                                                                            sort_key = lambda x: len(x.Text),\n",
    "                                                                            batch_size = self.Batch_size,\n",
    "                                                                            device = self.device)\n",
    "        print(f\"Label vocab_freq: {self.LABEL.vocab.freqs}\")\n",
    "        \n",
    "    def tokenizer(self, text):\n",
    "        return [tok for tok in word_tokenize(text)]\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_dim, emb_dim, hid_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(in_dim, emb_dim)\n",
    "        self.rnn = nn.RNN(emb_dim, hid_dim)\n",
    "        self.fc = nn.Linear(hid_dim, out_dim)\n",
    "    def forward(self, x):\n",
    "        # dimension of x: [sentence_len, batch_size]\n",
    "        embedded = self.embedding(x)  # dimension of embedded: [sentence_len, batch_size, embed_dim] \n",
    "        output, hidden = self.rnn(embedded) # dimension of output and hidden: [sentence_len, batch_size, hid_dim] , [1, batch_size, embed_dim]\n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        output =  self.fc(hidden)\n",
    "        return out\n",
    "    def train(self, model, iterator, optimizer, criterion):\n",
    "        pass\n",
    "    def evaluate(self,model, iterator,criterion):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d8ef1d5e-b983-4d6b-a235-64b88d54f031",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Despite', 'the', 'fact', 'that', 'I', 'have', 'only', 'played', 'a', 'small'] 124288\n"
     ]
    }
   ],
   "source": [
    "tokens = [words for sent in df[\"review\"] for words in sent.split(\" \")][:124288]\n",
    "print(tokens[:10], len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79b7a0fa-67c1-4591-ab26-e37385ea9c6e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed tensors: {'transformer': {'token_ids': tensor([216,  42, 279,  ...,  76,  48,  27]), 'mask': tensor([True, True, True,  ..., True, True, True]), 'type_ids': tensor([0, 0, 0,  ..., 0, 0, 0]), 'wordpiece_mask': tensor([True, True, True,  ..., True, True, True]), 'offsets': tensor([[     0,      4],\n",
      "        [     5,      5],\n",
      "        [     6,      7],\n",
      "        ...,\n",
      "        [307242, 307243],\n",
      "        [307244, 307250],\n",
      "        [307251, 307251]])}}\n",
      "Embedded tokens size: torch.Size([1, 124288, 512])\n"
     ]
    }
   ],
   "source": [
    "elmo_model = elmo(tokens=tokens)\n",
    "embedded_tokens = elmo_model.embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "46ce9466-68da-4434-ad16-5292ebbd27d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchtext/data/utils.py:123: UserWarning:Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of TRAIN_data: 8000,Length of TEST_data: 4000 \n",
      "Unique tokens in :\n",
      "TEXT vocab:4532,\n",
      "LABEL vocab:2\n",
      "Label vocab_freq: Counter({'2': 4079, '1': 3921})\n"
     ]
    }
   ],
   "source": [
    "glove_model = glove_embed()\n",
    "TEXT = glove_model.TEXT\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 374\n",
    "OUTPUT_DIM = 2\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1428fd-a300-4abd-bca4-6193139496f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
